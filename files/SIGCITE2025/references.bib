@inproceedings{a.alghamdiChallengesSecureSoftware2022,
  title = {Challenges of {{Secure Software Deployment}}: {{An Empirical Study}}},
  shorttitle = {Challenges of {{Secure Software Deployment}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}} 2022},
  author = {A. Alghamdi, Azzah and Niazi, Mahmood},
  year = {2022},
  month = jun,
  series = {{{EASE}} '22},
  pages = {440--445},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3530019.3531337},
  url = {https://doi.org/10.1145/3530019.3531337},
  urldate = {2022-09-18},
  isbn = {978-1-4503-9613-4},
  keywords = {challenges,Cybersecurity,Finished,Industry,IT organizations,Software deployment,Unrelated},
  annotation = {0 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\BMFNYUAX\A. Alghamdi_Niazi_2022_Challenges of Secure Software Deployment.pdf}
}

@article{abdulrahmanabuelkhailRelatingCodeSmells2019,
  title = {On {{Relating Code Smells}} to {{Security Vulnerabilities}}},
  author = {{Abdulrahman Abu Elkhail} and {Tomas Cerny}},
  year = {2019},
  month = may,
  journal = {2019 IEEE 5th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)},
  pages = {7--12},
  publisher = {IEEE},
  address = {Washington, DC, USA},
  doi = {10.1109/BigDataSecurity-HPSC-IDS.2019.00013},
  url = {https://ieeexplore.ieee.org/document/8819456/},
  urldate = {2023-06-21},
  abstract = {In recent years there has been an abundance of well-known software design problems that fall under a variety of different terms such as flaws or code smells. Nowadays software systems place considerable importance to security concerns related to code flaws that lead to software vulnerabilities. In this paper, we present a study to identify the relationship between code smells and vulnerabilities in software code. Our study provides information about the impact of code smells on software security and considers open source implementation of technologies under the Apache Tomcat software. The results show the relationship between the code smells and the security vulnerabilities. While most code smells, have a slight impact, one particular smell is identified to have a more considerable impact.},
  isbn = {9781728100067},
  annotation = {7 citations (Crossref) [2023-06-23]},
  file = {C:\Users\Andrew\Zotero\storage\QTEGYAVC\Elkhail_Cerny_2019_On Relating Code Smells to Security Vulnerabilities.pdf}
}

@misc{abetAccreditationChanges,
  title = {Accreditation {{Changes}}},
  author = {{ABET}},
  url = {https://www.abet.org/accreditation/accreditation-criteria/accreditation-changes/},
  urldate = {2023-02-02},
  langid = {american},
  keywords = {Student/Academia},
  file = {C:\Users\Andrew\Zotero\storage\HRM4WPFP\accreditation-changes.html}
}

@inproceedings{acarYouGetWhere2016,
  title = {You {{Get Where You}}'re {{Looking}} for: {{The Impact}} of {{Information Sources}} on {{Code Security}}},
  shorttitle = {You {{Get Where You}}'re {{Looking}} For},
  booktitle = {2016 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  author = {Acar, Yasemin and Backes, Michael and Fahl, Sascha and Kim, Doowon and Mazurek, Michelle L. and Stransky, Christian},
  year = {2016},
  month = may,
  pages = {289--305},
  issn = {2375-1207},
  doi = {10.1109/SP.2016.25},
  url = {https://ieeexplore.ieee.org/document/7546508},
  urldate = {2024-09-09},
  abstract = {Vulnerabilities in Android code -- including but not limited to insecure data storage, unprotected inter-component communication, broken TLS implementations, and violations of least privilege -- have enabled real-world privacy leaks and motivated research cataloguing their prevalence and impact. Researchers have speculated that appification promotes security problems, as it increasingly allows inexperienced laymen to develop complex and sensitive apps. Anecdotally, Internet resources such as Stack Overflow are blamed for promoting insecure solutions that are naively copy-pasted by inexperienced developers. In this paper, we for the first time systematically analyzed how the use of information resources impacts code security. We first surveyed 295 app developers who have published in the Google Play market concerning how they use resources to solve security-related problems. Based on the survey results, we conducted a lab study with 54 Android developers (students and professionals), in which participants wrote security-and privacy-relevant code under time constraints. The participants were assigned to one of four conditions: free choice of resources, Stack Overflow only, official Android documentation only, or books only. Those participants who were allowed to use only Stack Overflow produced significantly less secure code than those using, the official Android documentation or books, while participants using the official Android documentation produced significantly less functional code than those using Stack Overflow. To assess the quality of Stack Overflow as a resource, we surveyed the 139 threads our participants accessed during the study, finding that only 25\% of them were helpful in solving the assigned tasks and only 17\% of them contained secure code snippets. In order to obtain ground truth concerning the prevalence of the secure and insecure code our participants wrote in the lab study, we statically analyzed a random sample of 200,000 apps from Google Play, finding that 93.6\% of the apps used at least one of the API calls our participants used during our study. We also found that many of the security errors made by our participants also appear in the wild, possibly also originating in the use of Stack Overflow to solve programming problems. Taken together, our results confirm that API documentation is secure but hard to use, while informal documentation such as Stack Overflow is more accessible but often leads to insecurity. Given time constraints and economic pressures, we can expect that Android developers will continue to choose those resources that are easiest to use, therefore, our results firmly establish the need for secure-but-usable documentation.},
  keywords = {Android,Androids,developer resources,developer study,Documentation,Humanoid robots,Mobile communication,Privacy,Programming,security,Security,usability,Vulnerability Research},
  annotation = {144 citations (Crossref) [2024-09-09]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\IFR2YSI5\\Acar et al_2016_You Get Where You're Looking for.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\3MNV4LAR\\7546508.html}
}

@article{allodiMeasuringAccuracySoftware2020,
  title = {Measuring the Accuracy of Software Vulnerability Assessments: Experiments with Students and Professionals},
  shorttitle = {Measuring the Accuracy of Software Vulnerability Assessments},
  author = {Allodi, Luca and Cremonini, Marco and Massacci, Fabio and Shim, Woohyun},
  year = {2020},
  month = mar,
  journal = {Empirical Software Engineering},
  volume = {25},
  number = {2},
  pages = {1063--1094},
  issn = {1382-3256, 1573-7616},
  doi = {10.1007/s10664-019-09797-4},
  url = {http://link.springer.com/10.1007/s10664-019-09797-4},
  urldate = {2023-01-16},
  abstract = {Abstract                            Assessing the risks of software vulnerabilities is a key process of software development and security management. This assessment requires to consider multiple factors (technical features, operational environment, involved assets, status of the vulnerability lifecycle, etc.) and may depend from the assessor's knowledge and skills. In this work, we tackle with an important part of this problem by measuring the accuracy of               technical               vulnerability assessments by assessors with different level and type of knowledge. We report an experiment to compare how accurately students with different technical education and security professionals are able to assess the severity of software vulnerabilities with the Common Vulnerability Scoring System (v3) industry methodology. Our results could be useful for increasing awareness about the intrinsic subtleties of vulnerability risk assessment and possibly better compliance with regulations. With respect to academic education, professional training and human resources selections our work suggests that measuring the effects of knowledge and expertise on the accuracy of software security assessments is feasible albeit not easy.},
  langid = {english},
  keywords = {Industry,Student/Academia},
  annotation = {6 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\EVCMWP6Z\\Allodi et al_2020_Measuring the accuracy of software vulnerability assessments.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\WUYQ5MBU\\Allodi et al_2020_Measuring the accuracy of software vulnerability assessments.pdf}
}

@inproceedings{almansooriFindingMissingPieces2023,
  title = {Towards {{Finding}} the {{Missing Pieces}} to {{Teach Secure Programming Skills}} to {{Students}}},
  booktitle = {Proceedings of the 54th {{ACM Technical Symposium}} on {{Computer Science Education V}}. 1},
  author = {Almansoori, Majed and Lam, Jessica and Fang, Elias and Soosai Raj, Adalbert Gerald and Chatterjee, Rahul},
  year = {2023},
  month = mar,
  series = {{{SIGCSE}} 2023},
  pages = {973--979},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3545945.3569730},
  url = {https://dl.acm.org/doi/10.1145/3545945.3569730},
  urldate = {2023-09-29},
  abstract = {Research efforts tried to expose students to security topics early in the undergraduate CS curriculum. However, such efforts are rarely adopted in practice and remain less effective when it comes to writing secure code. In our prior work [18], we identified key issues with the how students code and grouped them into six themes: (a) Knowledge of C, (b) Understanding compiler and OS messages, (c) Utilization of resources, (d) Knowledge of memory, (e) Awareness of unsafe functions, and (f) Understanding of security topics. In this work, we aim to understand students' knowledge about each theme and how that knowledge affects their secure coding practices. Thus, we propose a modified SOLO taxonomy for the latter five themes. We apply the taxonomy to the coding interview data of 21 students from two US R1 universities. Our results suggest that most students have limited knowledge of each theme. We also show that scoring low in these themes correlates with why students fail to write secure code and identify possible vulnerabilities.},
  isbn = {978-1-4503-9431-4},
  keywords = {computer systems,solo taxonomy,Student/Academia,teaching security},
  annotation = {0 citations (Crossref) [2023-10-03]},
  file = {C:\Users\Andrew\Zotero\storage\HHQP6TMU\Almansoori et al_2023_Towards Finding the Missing Pieces to Teach Secure Programming Skills to.pdf}
}

@inproceedings{almansooriHowSecureAre2020,
  title = {How {{Secure}} Are Our {{Computer Systems Courses}}?},
  booktitle = {Proceedings of the 2020 {{ACM Conference}} on {{International Computing Education Research}}},
  author = {Almansoori, Majed and Lam, Jessica and Fang, Elias and Mulligan, Kieran and Soosai Raj, Adalbert Gerald and Chatterjee, Rahul},
  year = {2020},
  month = aug,
  series = {{{ICER}} '20},
  pages = {271--281},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3372782.3406266},
  url = {https://dl.acm.org/doi/10.1145/3372782.3406266},
  urldate = {2024-10-30},
  abstract = {Introductory computer systems courses teach students how a single program is executed inside a computer, providing them with their first exposure to the logical internals of computing systems. This is one of the first introductory courses where students can learn about security and the need for robust coding. However, currently, these courses are taught with a focus on functionality and efficiency only, ignoring security almost entirely.In this paper, we provide a basic security analysis of computer systems courses from 16 of the top 20 CS undergraduate programs at R1 universities in the US. We collected more than 760 thousand lines of C/C++ code written by 253 students and used by instructors in lectures and for assignments. We found students frequently use unsafe functions such as strcpy, strcat, and system, many of which can lead to serious security vulnerabilities. These unsafe functions are present in course materials such as in lecture slides and textbooks, and even in the code provided by instructors. We also show a high correlation between the unsafe functions used by students with those used by their instructors.},
  isbn = {978-1-4503-7092-9},
  keywords = {Student/Academia},
  file = {C:\Users\Andrew\Zotero\storage\IE7F6Z9H\Almansoori et al. - 2020 - How Secure are our Computer Systems Courses.pdf}
}

@article{alonCode2seqGeneratingSequences2018,
  title = {Code2seq: {{Generating Sequences}} from {{Structured Representations}} of {{Code}}},
  shorttitle = {Code2seq},
  author = {Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran},
  year = {2018},
  month = aug,
  journal = {ArXiv},
  url = {https://www.semanticscholar.org/paper/code2seq%3A-Generating-Sequences-from-Structured-of-Alon-Brody/98d1307bed619b58b4a44acd8e65ac58495776c2},
  urldate = {2023-02-01},
  abstract = {The ability to generate natural language sequences from source code snippets has a variety of applications such as code summarization, documentation, and retrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine translation (NMT), have achieved state-of-the-art performance on these tasks by treating source code as a sequence of tokens. We present \$\{{\textbackslash}rm \{{\textbackslash}scriptsize CODE2SEQ\}\}\$: an alternative approach that leverages the syntactic structure of programming languages to better encode source code. Our model represents a code snippet as the set of compositional paths in its abstract syntax tree (AST) and uses attention to select the relevant paths while decoding. We demonstrate the effectiveness of our approach for two tasks, two programming languages, and four datasets of up to \$16\$M examples. Our model significantly outperforms previous models that were specifically designed for programming languages, as well as state-of-the-art NMT models. An interactive online demo of our model is available at this http URL Our code, data and trained models are available at this http URL},
  file = {C:\Users\Andrew\Zotero\storage\8DC76CVT\Alon et al_2018_code2seq.pdf}
}

@article{alonCode2vecLearningDistributed2019,
  title = {Code2vec: Learning Distributed Representations of Code},
  shorttitle = {Code2vec},
  author = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
  year = {2019},
  month = jan,
  journal = {Implementation, data and a trained model for the code2vec paper},
  volume = {3},
  number = {POPL},
  pages = {40:1--40:29},
  doi = {10.1145/3290353},
  url = {https://dl.acm.org/doi/10.1145/3290353},
  urldate = {2024-09-08},
  abstract = {We present a neural model for representing snippets of code as continuous distributed vectors (``code embeddings''). The main idea is to represent a code snippet as a single fixed-length code vector, which can be used to predict semantic properties of the snippet. To this end, code is first decomposed to a collection of paths in its abstract syntax tree. Then, the network learns the atomic representation of each path while simultaneously learning how to aggregate a set of them.  We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 12M methods. We show that code vectors trained on this dataset can predict method names from files that were unobserved during training. Furthermore, we show that our model learns useful method name vectors that capture semantic similarities, combinations, and analogies.  A comparison of our approach to previous techniques over the same dataset shows an improvement of more than 75\%, making it the first to successfully predict method names based on a large, cross-project corpus. Our trained model, visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code, data and trained models are available at https://github.com/tech-srl/code2vec.},
  annotation = {675 citations (Crossref) [2024-09-08]},
  file = {C:\Users\Andrew\Zotero\storage\RC48G488\Alon et al_2019_code2vec.pdf}
}

@article{amoCybersecurityInterventionsTeens2019,
  title = {Cybersecurity {{Interventions}} for {{Teens}}: {{Two Time-Based Approaches}}},
  shorttitle = {Cybersecurity {{Interventions}} for {{Teens}}},
  author = {Amo, Laura C. and Liao, Ruochen and Frank, Emma and Rao, H. Raghav and Upadhyaya, Shambhu},
  year = {2019},
  month = may,
  journal = {IEEE Transactions on Education},
  volume = {62},
  number = {2},
  pages = {134--140},
  issn = {1557-9638},
  doi = {10.1109/TE.2018.2877182},
  abstract = {Contribution: Intervention effectiveness is shown to vary in its influence on teenagers' outcomes with cybersecurity problem-solving and engagement. In-depth, high-intensity types of intervention may be more effective for female students. Background: Instructional interventions are being developed to address both the critical shortage in cybersecurity talent and gender gaps in the cyber workforce. These interventions need rigorous evaluation. Specific types of instructional strategies are particularly effective for STEM learning. Also, gender differences are found in the benefit students derive from certain instructional methods. An important question is whether certain instructional methods are particularly effective for cybersecurity learning, and consistent in both male and female students. Research Questions: Do cybersecurity interventions affect problem-solving, cybersecurity engagement, and/or cybersecurity self-efficacy? Are there gender differences in terms of intervention effectiveness? Methodology: Study 1 ( \$n{\textbackslash},{\textbackslash}, =\$ 79) included a 60-min workshop model where participants, assigned to treatment and control groups, completed surveys pre- and post-intervention. The treatment group experienced a workshop on computer networking, without any technology. The control group did not receive the workshop. Study 2 ( \$n{\textbackslash},{\textbackslash},=\$ 34) was a week-long intervention whose participants had formal lessons, built websites, and defended themselves from an ongoing simulated cyberattack. Participants completed a survey on cybersecurity learning and engagement three times during the intervention. Findings: Study 1 showed no main treatment effect, but females experienced greater gains in problem-solving than males. In Study 2, there was positive growth over time and females experienced greater growth in cybersecurity self-efficacy relative to males.},
  keywords = {Computational modeling,Computer awareness,Computer science,Conferences,cyber skills,cybersecurity education,Education,engagement,Engineering profession,gender,middle school,Problem-solving,scale development,Student/Academia},
  annotation = {4 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\PQK6E22X\\Amo et al_2019_Cybersecurity Interventions for Teens.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\H74AQ6XK\\8548564.html}
}

@article{banganiSACLA2019Authors,
  title = {{{SACLA}} 2019 {\copyright} {{The}} Authors/{{SACLA}}},
  author = {Bangani, Sifiso and Futcher, Lynn and Van, Johan},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\3PIVCWG9\Bangani et al. - SACLA 2019 Â© The authorsSACLA.pdf}
}

@inproceedings{berisfordCanGamificationHelp2022,
  title = {Can Gamification Help to Teach {{Cybersecurity}}?},
  booktitle = {2022 20th {{International Conference}} on {{Information Technology Based Higher Education}} and {{Training}} ({{ITHET}})},
  author = {Berisford, Christopher J and Blackburn, Leighton and Ollett, Jennifer M and Tonner, Thomas B and Yuen, Chun San Hugh and Walton, Ryan and Olayinka, Olakunle},
  year = {2022},
  month = nov,
  pages = {1--9},
  issn = {2380-1603},
  doi = {10.1109/ITHET56107.2022.10031716},
  url = {https://ieeexplore.ieee.org/document/10031716},
  urldate = {2024-11-20},
  abstract = {Over the last decade, there has been an increase in the number of attacks on web applications. The proliferation of these attacks is partially a result of increased adoption of IT systems in organisations and the increasing role digital technologies play in our lives. The success of an attack relies upon the existence of vulnerabilities in the code base and there is consensus within literature that many of these vulnerabilities can be avoided through developers adopting secure code practices and standards which are often not formally taught.Whilst gamification has been shown to be an effective educational tool in fields such as health, education and security awareness, there is a scarcity of research regarding the application of gamification in the context of secure code practices. This paper evaluates the efficacy of a bespoke gamified application in creating awareness and fostering an understanding of the threats and secure coding practices. The application presented in this work focuses on JavaScript with the aim of reducing the number of vulnerabilities in web applications. The analysis is conducted using first and second-year undergraduate participants, who are viewed as the primary target for this software.As part of a participant study involving the application, it was found that gamification elements were effective in increasing user engagement. Initial findings suggest potential for the integration of secure-code gamification in traditional pedagogical methods, but further investigation is required to strengthen this claim.},
  keywords = {Codes,Correlation,cybersecurity,developers,Encoding,game-based learning,gamification,Information technology,Market research,secure coding,Software,Training},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\NTV8URWJ\\Berisford et al. - 2022 - Can gamification help to teach Cybersecurity.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\P32N2MMP\\10031716.html}
}

@article{bishopClinicSecureProgramming2010,
  title = {A {{Clinic}} for "{{Secure}}" {{Programming}}},
  author = {Bishop, Matt},
  year = {2010},
  month = mar,
  journal = {IEEE Security \& Privacy},
  volume = {8},
  number = {2},
  pages = {54--56},
  issn = {1558-4046},
  doi = {10.1109/MSP.2010.62},
  url = {https://ieeexplore.ieee.org/document/5439528},
  urldate = {2024-10-30},
  abstract = {In this paper, the author mentions that despite the reliance on software in everything from televisions and cars to medical equipment, it often doesn't work correctly. Everyone has had problems with software like text editors that freeze, answering machines that won't answer. Others are far more serious, such as the program on a satellite that contains an error, causing the loss of expensive equipment, or Web servers that have bugs enabling an attacker to break in and steal personal data. In the case of medical equipment, poor software could cost lives. To develop a better software, one way is to make good programming as much a part of learning computer science as good writing is a part of studying English and law. To test this idea, a secure-programming clinic was developed. Principles of robust programming are widely taught in beginning and advanced programming courses. They're a large part of good programming style and require the realization that things can go wrong. A user might enter a string when the program expects an integer. A function that opens a file might fail. The program must check for these possibilities and handle them correctly. Grading in these programming courses takes such practices into account. But all too often in advanced computer science courses, students don't follow these practices.},
  keywords = {Biomedical equipment,Computer bugs,Computer science,Costs,programming,robust programming,Robustness,Satellite broadcasting,security and privacy,software engineering,software engineering education,Student/Academia,Testing,TV,Web server,Writing,writing clinics},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\AY5DYCAC\\Bishop - 2010 - A Clinic for Secure Programming.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\UBGRU97L\\5439528.html}
}

@misc{BlackHat,
  title = {Black {{Hat}}},
  url = {https://www.blackhat.com/us-23/briefings/schedule/index.html#lost-control-breaking-hardware-assisted-kernel-control-flow-integrity-with-page-oriented-programming-32061},
  urldate = {2023-08-30},
  abstract = {Black Hat}
}

@article{bosuPeerCodeReview2013,
  title = {Peer {{Code Review}} to {{Prevent Security Vulnerabilities}}: {{An Empirical Evaluation}}},
  shorttitle = {Peer {{Code Review}} to {{Prevent Security Vulnerabilities}}},
  author = {Bosu, Amiangshu and Carver, Jeffrey C.},
  year = {2013},
  month = jun,
  journal = {2013 IEEE Seventh International Conference on Software Security and Reliability Companion},
  pages = {229--230},
  publisher = {IEEE},
  address = {Gaithersburg, MD, USA},
  doi = {10.1109/SERE-C.2013.22},
  url = {http://ieeexplore.ieee.org/document/6616350/},
  urldate = {2023-02-01},
  abstract = {Peer code review, as an effective quality improvement practice, has also been considered important for reducing security vulnerabilities. There is a lack of empirical evidence to quantify and support this claim. Therefore, we propose a research plan to analyze mature open source projects to gather empirical evidence regarding the relationship between peer code review and security vulnerabilities. As a proof-of-concept, we analyzed the Chromium OS project and found that reviewers identified potential vulnerabilities in 32 review requests.},
  isbn = {9781479929252 9781479929245},
  annotation = {10 citations (Crossref) [2023-02-16]}
}

@inproceedings{boswellUtilizingConvolutionalNeural2024,
  title = {Utilizing {{Convolutional Neural Networks}} and {{Eye-Tracking Data}} for {{Classroom Attention Tracking}}},
  booktitle = {Proceedings of the 57th {{Hawaii International Conference}} on {{System Sciences}} ({{HICSS-57}})},
  author = {Boswell, Bradley and Sanders, Andrew and Walia, Gursimran and Allen, Andrew},
  year = {2024},
  month = jan,
  url = {https://hdl.handle.net/10125/107021},
  urldate = {2024-05-17},
  copyright = {All rights reserved},
  isbn = {978-0-9981331-7-1},
  langid = {english},
  keywords = {Finished,Unrelated},
  file = {C:\Users\Andrew\Zotero\storage\CL58B79X\Boswell et al_2024_Utilizing Convolutional Neural Networks and Eye-Tracking Data for Classroom.pdf}
}

@article{cabajCybersecurityEducationEvolution2018,
  title = {Cybersecurity Education: {{Evolution}} of the Discipline and Analysis of Master Programs},
  shorttitle = {Cybersecurity Education},
  author = {Cabaj, Krzysztof and Domingos, Dulce and Kotulski, Zbigniew and Resp{\'i}cio, Ana},
  year = {2018},
  month = jun,
  journal = {Computers \& Security},
  volume = {75},
  pages = {24--35},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2018.01.015},
  url = {https://www.sciencedirect.com/science/article/pii/S0167404818300373},
  urldate = {2023-01-18},
  abstract = {As the amount of information, critical services, and interconnected computers and ``things'' in the cyberspace is steadily increasing, the number, sophistication, and impact of cyberattacks are becoming more and more significant. In the last decades, governmental and non-governmental organisations have become aware of this problem. However, the existing cybersecurity workforce has not been sufficient for satisfying the increasing demand for qualified cybersecurity professionals, and the shortfall will increase in the next years. Meanwhile, to address the increasing demand for cybersecurity professionals, academic institutions have been establishing cybersecurity programs, particularly, cybersecurity master programs. This paper aims at analysing which cybersecurity topics are covered by existing cybersecurity master programs of top universities and how these topics are distributed through courses. It starts by reviewing the evolution and maturation of the cybersecurity discipline, focusing on the ACM efforts, which include the early addition of the Information Assurance and Security Knowledge Areas to the computer science curricula and, more recently, the development of curricular recommendations to support the definition of post-secondary cybersecurity programs. These latest guidelines are used to analyse and review 21 cybersecurity master programs, focusing on the contents of their courses, structure, admission requirements, duration, requirements for completion, and evolution.},
  langid = {english},
  keywords = {Comparative study,Cybersecurity curricula,Cybersecurity discipline evolution,Cybersecurity master programs,Finished,Graduate cybersecurity education,Student/Academia},
  annotation = {44 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\4NI7HEYD\\Cabaj et al_2018_Cybersecurity education.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\IFG95EZ5\\S0167404818300373.html}
}

@misc{carverTestingTutorNSF,
  title = {Testing {{Tutor NSF Grant Description}}},
  author = {Carver, Jeffrey and Cordova, Lucas and Walia, Gursimran},
  keywords = {Student/Academia,Unrelated},
  file = {C:\Users\Andrew\Zotero\storage\HZC6JEHR\Carver et al_Testing Tutor NSF Grant Description.pdf}
}

@misc{chenDiverseVulNewVulnerable2023,
  title = {{{DiverseVul}}: {{A New Vulnerable Source Code Dataset}} for {{Deep Learning Based Vulnerability Detection}}},
  shorttitle = {{{DiverseVul}}},
  author = {Chen, Yizheng and Ding, Zhoujie and Chen, Xinyun and Wagner, David},
  year = {2023},
  month = apr,
  number = {arXiv:2304.00409},
  eprint = {2304.00409},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.00409},
  url = {http://arxiv.org/abs/2304.00409},
  urldate = {2023-05-26},
  abstract = {We propose and release a new vulnerable source code dataset. We curate the dataset by crawling security issue websites, extracting vulnerability-fixing commits and source codes from the corresponding projects. Our new dataset contains 150 CWEs, 26,635 vulnerable functions, and 352,606 non-vulnerable functions extracted from 7,861 commits. Our dataset covers 305 more projects than all previous datasets combined. We show that increasing the diversity and volume of training data improves the performance of deep learning models for vulnerability detection. Combining our new dataset with previous datasets, we present an analysis of the challenges and promising research directions of using deep learning for detecting software vulnerabilities. We study 11 model architectures belonging to 4 families. Our results show that deep learning is still not ready for vulnerability detection, due to high false positive rate, low F1 score, and difficulty of detecting hard CWEs. In particular, we demonstrate an important generalization challenge for the deployment of deep learning-based models. However, we also identify hopeful future research directions. We demonstrate that large language models (LLMs) are the future for vulnerability detection, outperforming Graph Neural Networks (GNNs) with manual feature engineering. Moreover, developing source code specific pre-training objectives is a promising research direction to improve the vulnerability detection performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Software Engineering},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\GTETTPRB\\Chen et al_2023_DiverseVul.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\FF8YQJFC\\2304.html}
}

@inproceedings{chiTeachingSecureCoding2013,
  title = {Teaching {{Secure Coding Practices}} to {{STEM Students}}},
  booktitle = {Proceedings of the 2013 on {{InfoSecCD}} '13: {{Information Security Curriculum Development Conference}}},
  author = {Chi, Hongmei and Jones, Edward L. and Brown, John},
  year = {2013},
  month = oct,
  series = {{{InfoSecCD}} '13},
  pages = {42--48},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2528908.2528911},
  url = {https://doi.org/10.1145/2528908.2528911},
  urldate = {2022-09-18},
  abstract = {Our experiences show that the earlier students learn secure coding concepts, even at the same time as they first learn to write code, the better they will continue using secure coding practices. In this paper, modules for teaching secure coding practices to STEM students are built and those modules are ready for most common programming courses for STEM students. Those modules will provide the essential and fundamental skills to programmers and application developers in secure programming. In addition, most of the modules will use static-analysis tools to help with detecting vulnerabilities in any given code. In addition, some survey's results are reposted here.},
  isbn = {978-1-4503-2547-9},
  keywords = {Secure coding practices,security vulnerabilities,static-analysis tools,STEM education,Student/Academia},
  annotation = {6 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\CJF5BUID\\chi2013.pdf.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\MME34WHV\\Chi et al. - 2013 - Teaching Secure Coding Practices to STEM Students.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\ZJXBIQL8\\Chi et al_2013_Teaching Secure Coding Practices to STEM Students.pdf}
}

@misc{CodeQualityTool,
  title = {Code {{Quality Tool}} \& {{Secure Analysis}} with {{SonarQube}}},
  url = {https://www.sonarsource.com/products/sonarqube/},
  urldate = {2023-06-19},
  abstract = {Empower development teams with a code quality \& security solution that deeply integrates into your enterprise environment that enables you to deploy Clean Code securely, consistently and reliably.},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\PEJ54QJH\sonarqube.html}
}

@article{collinsTeachingPracticeShaping2023,
  title = {Teaching by {{Practice}}: {{Shaping Secure Coding Mentalities}} through {{Cybersecurity CTFs}}},
  shorttitle = {Teaching by {{Practice}}},
  author = {Collins, Jazmin and Ford, Vitaly},
  year = {2023},
  month = jan,
  journal = {Journal of Cybersecurity Education, Research and Practice},
  volume = {2022},
  number = {2},
  issn = {2472-2707},
  doi = {10.32727/8.2023.8},
  url = {https://digitalcommons.kennesaw.edu/jcerp/vol2022/iss2/9},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\5DFPCLVR\\Collins and Ford - 2023 - Teaching by Practice Shaping Secure Coding Mentalities through Cybersecurity CTFs.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\WUVDPEQF\\9.html}
}

@inproceedings{cordovaComparisonInquiryBasedConceptual2021,
  title = {A {{Comparison}} of {{Inquiry-Based Conceptual Feedback}} vs. {{Traditional Detailed Feedback Mechanisms}} in {{Software Testing Education}}: {{An Empirical Investigation}}},
  shorttitle = {A {{Comparison}} of {{Inquiry-Based Conceptual Feedback}} vs. {{Traditional Detailed Feedback Mechanisms}} in {{Software Testing Education}}},
  booktitle = {Proceedings of the 52nd {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Cordova, Lucas and Carver, Jeffrey and Gershmel, Noah and Walia, Gursimran},
  year = {2021},
  month = mar,
  series = {{{SIGCSE}} '21},
  pages = {87--93},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3408877.3432417},
  url = {https://doi.org/10.1145/3408877.3432417},
  urldate = {2022-09-18},
  abstract = {The feedback provided by current testing education tools about the deficiencies in a student's test suite either mimics industry code coverage tools or lists specific instructor test cases that are missing from the student's test suite. While useful in some sense, these types of feedback are akin to revealing the solution to the problem, which can inadvertently encourage students to pursue a trial-and-error approach to testing, rather than using a more systematic approach that encourages learning. In addition to not teaching students why their test suite is inadequate, this type of feedback may motivate students to become dependent on the feedback rather than thinking for themselves. To address this deficiency, there is an opportunity to investigate alternative feedback mechanisms that include a positive reinforcement of testing concepts. We argue that using an inquiry-based learning approach is better than simply providing the answers. To facilitate this type of learning, we present Testing Tutor, a web-based assignment submission platform that supports different levels of testing pedagogy via a customizable feedback engine. We evaluated the impact of the different types of feedback through an empirical study in two sophomore-level courses. We use Testing Tutor to provide students with different types of feedback, either traditional detailed code coverage feedback or inquiry-based learning conceptual feedback, and compare the effects. The results show that students that receive conceptual feedback had higher code coverage (by different measures), fewer redundant test cases, and higher programming grades than the students who receive traditional code coverage feedback.},
  isbn = {978-1-4503-8062-1},
  keywords = {education,Finished,pedagogy,Student/Academia,testing,tools},
  annotation = {3 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\RNWZVEVX\Cordova et al_2021_A Comparison of Inquiry-Based Conceptual Feedback vs.pdf}
}

@inproceedings{crabbCriticalReviewCybersecurity2024,
  title = {A {{Critical Review}} of {{Cybersecurity Education}} in the {{United States}}},
  booktitle = {Proceedings of the 55th {{ACM Technical Symposium}} on {{Computer Science Education V}}. 1},
  author = {Crabb, James and Hundhausen, Christopher and Gebremedhin, Assefaw},
  year = {2024},
  month = mar,
  series = {{{SIGCSE}} 2024},
  pages = {241--247},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3626252.3630757},
  url = {https://dl.acm.org/doi/10.1145/3626252.3630757},
  urldate = {2024-11-10},
  abstract = {This work examines the state-of-the-art of cybersecurity education in the United States by considering two sources of data. The first source consists of Programs of Study for cybersecurity programs at Centers of Academic Excellence in Cybersecurity designated by the National Security Agency. Statistics were aggregated from a sample of one hundred CAE-C institutions, trends and gaps are identified, and improvements are proposed. The second source is peer-reviewed research published in the field of cybersecurity education over the last decade. A review of this literature shows a strong focus on identifying instructional content and developing educational tools while simultaneously indicating a shortage of research into rigorous evaluation of the instructional approaches being used to teach cybersecurity. Our review of these two sources of data highlight two paths to improving cybersecurity education in the United States. First, institutions offering cybersecurity degrees could work more closely with groups such as NIST, ACM, and IEEE to ensure their curricula match the needs of industry and they are graduating work-ready cybersecurity specialists. While CAE-C designation provides certain requirements for the amount of cybersecurity content included in curricula, designated institutions vary widely in the types of programs they offer and how many cybersecurity-specific courses they provide. Second, cybersecurity education could benefit from an influx of ideas from educational psychology regarding instructional theories such as cognitive load theory.},
  isbn = {9798400704239},
  file = {C:\Users\Andrew\Zotero\storage\SQSNFPG9\Crabb et al. - 2024 - A Critical Review of Cybersecurity Education in the United States.pdf}
}

@article{croftDataQualitySoftware2023,
  title = {Data {{Quality}} for {{Software Vulnerability Datasets}}},
  author = {Croft, Roland and Babar, M. Ali and Kholoosi, Mehdi},
  year = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2301.05456},
  url = {https://arxiv.org/abs/2301.05456},
  urldate = {2023-03-01},
  abstract = {The use of learning-based techniques to achieve automated software vulnerability detection has been of longstanding interest within the software security domain. These data-driven solutions are enabled by large software vulnerability datasets used for training and benchmarking. However, we observe that the quality of the data powering these solutions is currently ill-considered, hindering the reliability and value of produced outcomes. Whilst awareness of software vulnerability data preparation challenges is growing, there has been little investigation into the potential negative impacts of software vulnerability data quality. For instance, we lack confirmation that vulnerability labels are correct or consistent. Our study seeks to address such shortcomings by inspecting five inherent data quality attributes for four state-of-the-art software vulnerability datasets and the subsequent impacts that issues can have on software vulnerability prediction models. Surprisingly, we found that all the analyzed datasets exhibit some data quality problems. In particular, we found 20-71\% of vulnerability labels to be inaccurate in real-world datasets, and 17-99\% of data points were duplicated. We observed that these issues could cause significant impacts on downstream models, either preventing effective model training or inflating benchmark performance. We advocate for the need to overcome such challenges. Our findings will enable better consideration and assessment of software vulnerability data quality in the future.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Finished,FOS: Computer and information sciences,Software Engineering (cs.SE)},
  file = {C:\Users\Andrew\Zotero\storage\VYUZGB7B\Croft et al_2023_Data Quality for Software Vulnerability Datasets.pdf}
}

@misc{CWE2022CWE,
  title = {{{CWE}} - 2022 {{CWE Top}} 25 {{Most Dangerous Software Weaknesses}}},
  url = {https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html},
  urldate = {2023-02-16},
  file = {C:\Users\Andrew\Zotero\storage\F39EV9NZ\2022_cwe_top25.html}
}

@misc{CWECommonWeakness,
  title = {{{CWE}} - {{Common Weakness Enumeration}}},
  url = {https://cwe.mitre.org/index.html},
  urldate = {2023-02-22},
  file = {C:\Users\Andrew\Zotero\storage\77SH4KYW\index.html}
}

@misc{CWECWE699Software,
  title = {{{CWE}} - {{CWE-699}}: {{Software Development}} (4.10)},
  url = {https://cwe.mitre.org/data/definitions/699.html},
  urldate = {2023-03-08},
  file = {C:\Users\Andrew\Zotero\storage\FUN2TVCS\699.html}
}

@misc{CWEFrequentlyAsked,
  title = {{{CWE}} - {{Frequently Asked Questions}} ({{FAQ}})},
  url = {https://cwe.mitre.org/about/faq.html},
  urldate = {2023-03-08},
  file = {C:\Users\Andrew\Zotero\storage\TEJ2DXWQ\faq.html}
}

@article{denningMoreSecureSoftware2015,
  title = {Toward More Secure Software},
  author = {Denning, Dorothy E.},
  year = {2015},
  month = mar,
  journal = {Communications of the ACM},
  volume = {58},
  number = {4},
  pages = {24--26},
  issn = {0001-0782},
  doi = {10.1145/2736281},
  url = {https://doi.org/10.1145/2736281},
  urldate = {2023-02-01},
  abstract = {Two proposals intended to reduce flaws in software use two very different approaches for software security.},
  annotation = {11 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\GWBHADCS\Denning_2015_Toward more secure software.pdf}
}

@misc{departmentofhomelandsecurityus-certSoftwareAssurance,
  title = {Software {{Assurance}}},
  author = {{Department of Homeland Security, US-CERT}},
  url = {https://www.cisa.gov/sites/default/files/publications/infosheet \_SoftwareAssurance.pdf},
  urldate = {2023-07-11},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\5S9Z9ZFB\Software Assurance.pdf}
}

@article{deruvoUnderstandingSemanticStyle2018,
  title = {Understanding Semantic Style by Analysing Student Code},
  author = {De Ruvo, Giuseppe and Tempero, Ewan and {Luxton-Reilly}, Andrew and Rowe, Gerard B. and Giacaman, Nasser},
  year = {2018},
  month = jan,
  journal = {Proceedings of the 20th Australasian Computing Education Conference},
  pages = {73--82},
  publisher = {ACM},
  address = {Brisbane Queensland Australia},
  doi = {10.1145/3160489.3160500},
  url = {https://dl.acm.org/doi/10.1145/3160489.3160500},
  urldate = {2023-02-01},
  abstract = {Good coding style is recognised by the software engineering profession as being important, and this is reflected in the standard computing curricula. Feedback on some aspects of coding style is now commonly provided by IDEs and by tools such as Checkstyle, but this feedback focuses on coding standards that are largely based on syntax. However, some aspects of coding style relate to the semantics of code --- of the many ways to achieve some functionality, some are preferred because they are simpler, yet students struggle to create them. In this paper, we introduce the concept of semantic style, and in particular semantic style indicators that may be manifestations of poor knowledge of some programming concepts. We describe 16 semantic style indicators and demonstrate their prevalence in almost 19,000 code samples submitted by over 900 novice students. Half the students submitted code exhibiting two or more of these indicators, demonstrating the potential value to learn by providing feedback on semantic style. We also find many indicators are present in the code of students attending their fourth year of a highly competitive Software Engineering programme, demonstrating the need for more attention to teaching of semantic style issues.},
  isbn = {9781450363402},
  langid = {english},
  keywords = {Student/Academia,Unrelated},
  annotation = {13 citations (Crossref) [2023-02-16]}
}

@article{dieterpawelczakTeachingSecurityIntroductory2020,
  title = {Teaching {{Security}} in {{Introductory C-Programming Courses}}},
  author = {{Dieter Pawelczak}},
  year = {2020},
  month = jun,
  journal = {6th International Conference on Higher Education Advances (HEAd'20)},
  publisher = {Universitat Polit{\`e}cnica de Val{\`e}ncia},
  doi = {10.4995/HEAd20.2020.11114},
  url = {http://ocs.editorial.upv.es/index.php/HEAD/HEAd20/paper/view/11114},
  urldate = {2023-07-17},
  abstract = {The challenges in the age of digitalization demand that universities qualify their computer science and engineering graduates well with respect to IT Security (information technology security). In engineering education such lectures are often offered as an elective subject, only. We propose to teach security aspects with respect to robustness and correctness already in the introductory programming course and therefore to cover at least parts of the overall field of IT Security as a compulsory subject for all students. The paper describes the integration of some rules and recommendations from the SEI Cert C Coding Standard into our introductory C programming course and discusses our experience with the course over the last two years with respect to its contents, realization, evaluation and examination.},
  isbn = {9788490488119},
  keywords = {Finished,Student/Academia},
  annotation = {0 citations (Crossref) [2023-07-17]},
  file = {C:\Users\Andrew\Zotero\storage\YRIGNEGN\Pawelczak_2020_Teaching Security in Introductory C-Programming Courses.pdf}
}

@inproceedings{elbaumBugHuntMaking2007,
  title = {Bug {{Hunt}}: {{Making Early Software Testing Lessons Engaging}} and {{Affordable}}},
  shorttitle = {Bug {{Hunt}}},
  booktitle = {29th {{International Conference}} on {{Software Engineering}} ({{ICSE}}'07)},
  author = {Elbaum, Sebastian and Person, Suzette and Dokulil, Jon and Jorde, Matt},
  year = {2007},
  month = may,
  pages = {688--697},
  issn = {1558-1225},
  doi = {10.1109/ICSE.2007.23},
  url = {https://ieeexplore.ieee.org/document/4222630},
  abstract = {Software testing efforts account for a large part of software development costs. However, as educators, we struggle to properly prepare students to perform software testing activities. This struggle is caused by multiple factors: (1) it is challenging to effectively incorporate software testing into an already over-packed curriculum, (2) ad-hoc efforts to teach testing generally happen too late in the students' career, after bad habits have already been developed, and (3) these efforts lack the necessary institutional consistency and support to be effective. To address these challenges we created Bug Hunt, a web-based tutorial to engage students in learning software testing strategies. In this paper we describe the most interesting aspects of the tutorial including the lessons and feedback mechanisms, and the facilities for instructors to configure the tutorial and obtain automatic student assessment. We also present the lessons learned after two years of deployment.},
  keywords = {Computer science,Computer science education,Costs,Courseware,Engineering profession,Feedback,Finished,Performance evaluation,Programming profession,Software engineering,Software testing,Software Testing Education,Student/Academia,Web-based Tutorial.},
  annotation = {34 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\7QDCDNK8\\Elbaum et al_2007_Bug Hunt.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\AMVK3HR6\\Elbaum et al_2007_Bug Hunt.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\7KHFNJ7C\\4222630.html}
}

@article{ericsonEBookTeachersLearning2015,
  title = {An {{eBook}} for Teachers Learning {{CS}} Principles},
  author = {Ericson, Barbara and Guzdial, Mark and Morrison, Briana and Parker, Miranda and Moldavan, Matthew and Surasani, Lekha},
  year = {2015},
  month = nov,
  journal = {ACM Inroads},
  volume = {6},
  number = {4},
  pages = {84--86},
  issn = {2153-2184},
  doi = {10.1145/2829976},
  url = {https://dl.acm.org/doi/10.1145/2829976},
  urldate = {2024-11-21},
  file = {C:\Users\Andrew\Zotero\storage\4I8XHQTV\Ericson et al. - 2015 - An eBook for teachers learning CS principles.pdf}
}

@inproceedings{ericsonRunestonePlatformFree2020,
  title = {Runestone: {{A Platform}} for {{Free}}, {{On-line}}, and {{Interactive Ebooks}}},
  shorttitle = {Runestone},
  booktitle = {Proceedings of the 51st {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Ericson, Barbara J. and Miller, Bradley N.},
  year = {2020},
  month = feb,
  series = {{{SIGCSE}} '20},
  pages = {1012--1018},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3328778.3366950},
  url = {https://dl.acm.org/doi/10.1145/3328778.3366950},
  urldate = {2024-11-21},
  abstract = {The Runestone platform is open-source, extensible, and serves free ebooks to over 25,000 learners a day from around the world. The site hosts 18 ebooks for computing courses. Some of these ebook have been translated into several languages. There are ebooks for secondary computer science (AP CSP and AP CSA), CS1, CS2, data science, and web programming courses. The platform currently supports executable and editable examples in Python, Java, C, C++, HTML, JavaScript, Processing, and SQL. Runestone provides features for instructors, learners, authors, and researchers. Instructors can create a custom course from any of the existing ebooks and their students can register for that course. Instructors can create assignments from the existing material or author new problems, grade assignments, and visualize student progress. Learners can execute and modify examples and answer practice questions with immediate feedback. Runestone includes common practice types, such as multiple-choice questions, as well as some unique types, such as adaptive Parsons problems. Authors can modify the existing ebooks or write new ebooks using restructuredText: a markup language. Researchers can create and test new interactive features, run experiments, and analyze log file data. This paper describes the architecture of the platform, highlights some of the unique features, provides an overview of how instructors use the platform, summarizes the research studies conducted on the platform, and describes plans for future development.},
  isbn = {978-1-4503-6793-6},
  file = {C:\Users\Andrew\Zotero\storage\KM3U768J\Ericson and Miller - 2020 - Runestone A Platform for Free, On-line, and Interactive Ebooks.pdf}
}

@misc{ESGSurveyReport,
  title = {{{ESG Survey Report}}: {{Modern Application Development Security}} {\textbar} {{Veracode}}},
  url = {https://info.veracode.com/survey-report-esg-modern-application-development-security.html},
  urldate = {2023-07-12},
  file = {C:\Users\Andrew\Zotero\storage\53RZA8TS\survey-report-esg-modern-application-development-security.html}
}

@inproceedings{espinhagasibaAwarenessSecureCoding2020,
  title = {Awareness of {{Secure Coding Guidelines}} in the {{Industry}} - {{A First Data Analysis}}},
  booktitle = {2020 {{IEEE}} 19th {{International Conference}} on {{Trust}}, {{Security}} and {{Privacy}} in {{Computing}} and {{Communications}} ({{TrustCom}})},
  author = {Espinha Gasiba, Tiago and Lechner, Ulrike and {Pinto-Albuquerque}, Maria and Mendez Fernandez, Daniel},
  year = {2020},
  month = dec,
  pages = {345--352},
  issn = {2324-9013},
  doi = {10.1109/TrustCom50675.2020.00055},
  url = {https://ieeexplore.ieee.org/document/9343011},
  urldate = {2024-09-11},
  abstract = {Software needs to be secure, in particular, when deployed to critical infrastructures. Secure coding guidelines capture practices in industrial software engineering to ensure the security of code. This study aims to assess the level of awareness of secure coding in industrial software engineering, the skills of software developers to spot weaknesses in software code, avoid them, and the organizational support to adhere to coding guidelines. The approach draws on well-established theories of policy compliance, neutralization theory, and security-related stress and the authors' many years of experience in industrial software engineering and on lessons identified from training secure coding in the industry. The paper presents the questionnaire design for the online survey and the first analysis of data from the pilot study.},
  keywords = {Awareness,Best Practices,Conferences,Encoding,Games,Guidelines,Industries,Industry,Secure Coding,Security,Software,Software Development,Software engineering},
  annotation = {4 citations (Crossref) [2024-09-11]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\QE3728TB\\Espinha Gasiba et al_2020_Awareness of Secure Coding Guidelines in the Industry - A First Data Analysis.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\D9AYP76K\\9343011.html}
}

@inproceedings{fanCodeVulnerabilityDataset2020,
  title = {A {{C}}/{{C}}++ {{Code Vulnerability Dataset}} with {{Code Changes}} and {{CVE Summaries}}},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Mining Software Repositories}}},
  author = {Fan, Jiahao and Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
  year = {2020},
  month = sep,
  series = {{{MSR}} '20},
  pages = {508--512},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3379597.3387501},
  url = {https://doi.org/10.1145/3379597.3387501},
  urldate = {2023-01-18},
  abstract = {We collected a large C/C++ code vulnerability dataset from open-source Github projects, namely Big-Vul. We crawled the public Common Vulnerabilities and Exposures (CVE) database and CVE-related source code repositories. Specifically, we collected the descriptive information of the vulnerabilities from the CVE database, e.g., CVE IDs, CVE severity scores, and CVE summaries. With the CVE information and its related published Github code repository links, we downloaded all of the code repositories and extracted vulnerability related code changes. In total, Big-Vul contains 3,754 code vulnerabilities spanning 91 different vulnerability types. All these code vulnerabilities are extracted from 348 Github projects. All information is stored in the CSV format. We linked the code changes with the CVE descriptive information. Thus, our Big-Vul can be used for various research topics, e.g., detecting and fixing vulnerabilities, analyzing the vulnerability related code changes. Big-Vul is publicly available on Github.},
  isbn = {978-1-4503-7517-7},
  keywords = {C/C++ Code,Code Changes,Common Vulnerabilities and Exposures,Vulnerability Research},
  annotation = {27 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\PBT7SXA4\Fan et al_2020_A C-C++ Code Vulnerability Dataset with Code Changes and CVE Summaries.pdf}
}

@inproceedings{fischerStackOverflowConsidered2017,
  title = {Stack {{Overflow Considered Harmful}}? {{The Impact}} of {{Copy}}\&{{Paste}} on {{Android Application Security}}},
  shorttitle = {Stack {{Overflow Considered Harmful}}?},
  booktitle = {2017 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{SP}})},
  author = {Fischer, Felix and B{\"o}ttinger, Konstantin and Xiao, Huang and Stransky, Christian and Acar, Yasemin and Backes, Michael and Fahl, Sascha},
  year = {2017},
  month = may,
  pages = {121--136},
  issn = {2375-1207},
  doi = {10.1109/SP.2017.31},
  url = {https://ieeexplore.ieee.org/document/7958574},
  urldate = {2024-11-15},
  abstract = {Online programming discussion platforms such as Stack Overflow serve as a rich source of information for software developers. Available information include vibrant discussions and oftentimes ready-to-use code snippets. Previous research identified Stack Overflow as one of the most important information sources developers rely on. Anecdotes report that software developers copy and paste code snippets from those information sources for convenience reasons. Such behavior results in a constant flow of community-provided code snippets into production software. To date, the impact of this behaviour on code security is unknown. We answer this highly important question by quantifying the proliferation of security-related code snippets from Stack Overflow in Android applications available on Google Play. Access to the rich source of information available on Stack Overflow including ready-to-use code snippets provides huge benefits for software developers. However, when it comes to code security there are some caveats to bear in mind: Due to the complex nature of code security, it is very difficult to provide ready-to-use and secure solutions for every problem. Hence, integrating a security-related code snippet from Stack Overflow into production software requires caution and expertise. Unsurprisingly, we observed insecure code snippets being copied into Android applications millions of users install from Google Play every day. To quantitatively evaluate the extent of this observation, we scanned Stack Overflow for code snippets and evaluated their security score using a stochastic gradient descent classifier. In order to identify code reuse in Android applications, we applied state-of-the-art static analysis. Our results are alarming: 15.4\% of the 1.3 million Android applications we analyzed, contained security-related code snippets from Stack Overflow. Out of these 97.9\% contain at least one insecure code snippet.},
  keywords = {Android Application Security,Androids,Cryptography,Google,Humanoid robots,Libraries,Software,Software Development,Stack Overflow,Vulnerability Research},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\F3J55GIB\\Fischer et al. - 2017 - Stack Overflow Considered Harmful The Impact of Copy&Paste on Android Application Security.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\2GWDKAJ7\\7958574.html}
}

@inproceedings{fraserGamifyingSoftwareTesting2019,
  title = {Gamifying a {{Software Testing Course}} with {{Code Defenders}}},
  booktitle = {Proceedings of the 50th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Fraser, Gordon and Gambi, Alessio and Kreis, Marvin and Rojas, Jos{\'e} Miguel},
  year = {2019},
  month = feb,
  series = {{{SIGCSE}} '19},
  pages = {571--577},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3287324.3287471},
  url = {https://doi.org/10.1145/3287324.3287471},
  urldate = {2022-09-18},
  abstract = {Software testing is an essential skill for software developers, but it is challenging to get students engaged in this activity. The Code Defenders game addresses this problem by letting students compete over code under test by either introducing faults ("attacking") or by writing tests ("defending") to reveal these faults. In this paper, we describe how we integrated Code Defenders as a semester-long activity of an undergraduate and graduate level university course on software testing. We complemented the regular course sessions with weekly Code Defenders sessions, addressing challenges such as selecting suitable code to test, managing games, and assessing performance. Our experience and our data show that the integration of Code Defenders was well-received by students and led them to practice testing thoroughly. Positive learning effects are evident as student performance improved steadily throughout the semester.},
  isbn = {978-1-4503-5890-3},
  keywords = {mutation analysis,software engineering education,software testing education,testing game,unit testing},
  annotation = {16 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\A2KNWRWG\\Fraser et al_2019_Gamifying a Software Testing Course with Code Defenders.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\WE5D4U7T\\Fraser et al_2019_Gamifying a Software Testing Course with Code Defenders.pdf}
}

@article{fuLineVulTransformerbasedLinelevel2022,
  title = {{{LineVul}}: A Transformer-Based Line-Level Vulnerability Prediction},
  shorttitle = {{{LineVul}}},
  author = {Fu, Michael and Tantithamthavorn, Chakkrit},
  year = {2022},
  month = may,
  journal = {Proceedings of the 19th International Conference on Mining Software Repositories},
  pages = {608--620},
  publisher = {ACM},
  address = {Pittsburgh Pennsylvania},
  doi = {10.1145/3524842.3528452},
  url = {https://dl.acm.org/doi/10.1145/3524842.3528452},
  urldate = {2023-03-01},
  abstract = {Software vulnerabilities are prevalent in software systems, causing a variety of problems including deadlock, information loss, or system failures. Thus, early predictions of software vulnerabilities are critically important in safety-critical software systems. Various ML/DL-based approaches have been proposed to predict vulnerabilities at the file/function/method level. Recently, IVDetect (a graph-based neural network) is proposed to predict vulnerabilities at the function level. Yet, the IVDetect approach is still inaccurate and coarse-grained. In this paper, we propose LINEVUL, a Transformer-based line-level vulnerability prediction approach in order to address several limitations of the state-of-the-art IVDetect approach. Through an empirical evaluation of a large-scale real-world dataset with 188k+ C/C++ functions, we show that LINEVUL achieves (1) 160\%-379\% higher F1-measure for function-level predictions; (2) 12\%-25\% higher Top-10 Accuracy for line-level predictions; and (3) 29\%-53\% less Effort@20\%Recall than the baseline approaches, highlighting the significant advancement of LINEVUL towards more accurate and more cost-effective line-level vulnerability predictions. Our additional analysis also shows that our LINEVUL is also very accurate (75\%-100\%) for predicting vulnerable functions affected by the Top-25 most dangerous CWEs, highlighting the potential impact of our LINEVUL in real-world usage scenarios.},
  isbn = {9781450393034},
  langid = {english},
  annotation = {2 citations (Crossref) [2023-03-01]}
}

@misc{gasibaRankingSecureCoding2020,
  title = {Ranking {{Secure Coding Guidelines}} for {{Software Developer Awareness Training}} in the {{Industry}}},
  author = {Gasiba, T. and Lechner, U. and Cu{\'e}llar, Jorge and Zouitni, A.},
  year = {2020},
  url = {https://www.semanticscholar.org/paper/Ranking-Secure-Coding-Guidelines-for-Software-in-Gasiba-Lechner/6712c7daa2a614cf0ad7c89601033f1d4a45dd02},
  urldate = {2023-01-16},
  abstract = {A method is devised, based on publicly available real-world vulnerability databases and secure coding guideline databases, to rank important secure coding guidelines based on defined industry-relevant metrics to define priorities for a teaching curriculum on raising cybersecurity awareness of software developers on secure coding Guidelines. Secure coding guidelines are essential material used to train and raise awareness of software developers on the topic of secure software development. In industrial environments, since developer time is costly, and training and education is part of non-productive hours, it is important to address and stress the most important topics first. In this work, we devise a method, based on publicly available real-world vulnerability databases and secure coding guideline databases, to rank important secure coding guidelines based on defined industry-relevant metrics. The goal is to define priorities for a teaching curriculum on raising cybersecurity awareness of software developers on secure coding guidelines. Furthermore, we do a small comparison study by asking computer science students from university on how they rank the importance of secure coding guidelines and compare the outcome to our results.},
  langid = {english},
  keywords = {Industry,Student/Academia},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\B74FTXQY\\Gasiba et al_2020_Ranking Secure Coding Guidelines for Software Developer Awareness Training in.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\KIZYGKD8\\6712c7daa2a614cf0ad7c89601033f1d4a45dd02.html}
}

@article{harrisUsingBloomsWebbs2015a,
  title = {Using {{Bloom}}'s and {{Webb}}'s {{Taxonomies}} to {{Integrate Emerging Cybersecurity Topics}} into a {{Computic Curriculum}}},
  author = {Harris, Mark and Patten, Karen},
  year = {2015},
  month = jan,
  journal = {Journal of Information Systems Education},
  volume = {26},
  number = {3},
  pages = {219--234},
  issn = {2574-3872},
  url = {https://aisel.aisnet.org/jise/vol26/iss3/4},
  keywords = {Finished,Student/Academia},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\G6FRIM92\\Harris and Patten - 2015 - Using Bloom's and Webb's Taxonomies to Integrate Emerging Cybersecurity Topics into a Computic Curri.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\7S6BQGB4\\4.html}
}

@article{hazimhanifRiseSoftwareVulnerability2021,
  title = {The Rise of Software Vulnerability: {{Taxonomy}} of Software Vulnerabilities Detection and Machine Learning Approaches},
  shorttitle = {The Rise of Software Vulnerability},
  author = {{Hazim Hanif} and {Mohd Hairul Nizam Md Nasir} and {Mohd Faizal Ab Razak} and {Ahmad Firdaus} and {Nor Badrul Anuar}},
  year = {2021},
  month = apr,
  journal = {Journal of Network and Computer Applications},
  volume = {179},
  pages = {103009},
  issn = {1084-8045},
  doi = {10.1016/j.jnca.2021.103009},
  url = {https://www.sciencedirect.com/science/article/pii/S1084804521000369},
  urldate = {2023-01-11},
  abstract = {The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests' taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95\% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.},
  langid = {english},
  keywords = {Computer security,Deep learning,Finished,Industry,Machine learning,Software security,Software vulnerability detection,Student/Academia,Vulnerability Research},
  annotation = {18 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\UCF4CLFF\\Hanif et al_2021_The rise of software vulnerability.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\ZFRKXVLL\\Hanif et al_2021_The rise of software vulnerability.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\LIDIR7F5\\S1084804521000369.html}
}

@inproceedings{himbeaultStudentsInvestigatingPedagogy2024,
  title = {Students {{Investigating Pedagogy}}: {{A Project}} for {{Learning}} about {{Learning}} in {{CS}}},
  shorttitle = {Students {{Investigating Pedagogy}}},
  booktitle = {Proceedings of the 55th {{ACM Technical Symposium}} on {{Computer Science Education V}}. 1},
  author = {Himbeault, Lauren and Latulipe, Celine},
  year = {2024},
  month = mar,
  series = {{{SIGCSE}} 2024},
  pages = {505--511},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3626252.3630933},
  url = {https://dl.acm.org/doi/10.1145/3626252.3630933},
  urldate = {2024-11-12},
  abstract = {As part of a graduate topics course in Computer Science Education, computer science students on project teams were assigned to investigate an undergraduate CS course. Each team examined course materials, interviewed the faculty member teaching the course, observed a class session of the course, produced a report of their findings, and then developed a research question and plan that could potentially be explored in the context of that course. We report on an interview study conducted to investigate the value of this course project from the perspective of the graduate students enrolled and the faculty members observed. Our findings indicate that the graduate students developed a deeper understanding of pedagogical challenges in computer science and wanted to engage further on the project. Faculty participants wanted more time with the teams and found that participating in the project provided a unique opportunity to reflect on their teaching practices.},
  isbn = {9798400704239},
  keywords = {Student/Academia},
  file = {C:\Users\Andrew\Zotero\storage\JLKL9RHG\Himbeault and Latulipe - 2024 - Students Investigating Pedagogy A Project for Learning about Learning in CS.pdf}
}

@misc{HomeCVE,
  title = {Home {\textbar} {{CVE}}},
  url = {https://www.cve.org/},
  urldate = {2023-02-22}
}

@inproceedings{hooshangiCanSecurityMindset2015,
  title = {Can the {{Security Mindset Make Students Better Testers}}?},
  booktitle = {Proceedings of the 46th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Hooshangi, Sara and Weiss, Richard and Cappos, Justin},
  year = {2015},
  month = feb,
  series = {{{SIGCSE}} '15},
  pages = {404--409},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2676723.2677268},
  url = {https://doi.org/10.1145/2676723.2677268},
  urldate = {2023-01-18},
  abstract = {Writing secure code requires a programmer to think both as a defender and an attacker. One can draw a parallel between this model of thinking and techniques used in test-driven development, where students learn by thinking about how to effectively test their code and anticipate possible bugs. In this study, we analyzed the quality of both attack and defense code that students wrote for an assignment given in an introductory security class of 75 (both graduate and senior undergraduate levels) at NYU. We made several observations regarding students' behaviors and the quality of both their defensive and offensive code. We saw that student defensive programs (i.e., assignments) are highly unique and that their attack programs (i.e., test cases) are also relatively unique. In addition, we examined how student behaviors in writing defense programs correlated with their attack program's effectiveness. We found evidence that students who learn to write good defensive programs can write effective attack programs, but the converse is not true. While further exploration of causality is needed, our results indicate that a greater pedagogical emphasis on defensive security may benefit students more than one that emphasizes offense.},
  isbn = {978-1-4503-2966-8},
  keywords = {access control,python,security,Student/Academia,testing},
  annotation = {8 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\VPT796J2\Hooshangi et al_2015_Can the Security Mindset Make Students Better Testers.pdf}
}

@inproceedings{jeffreyBugFixLearningbasedTool2009,
  title = {{{BugFix}}: {{A}} Learning-Based Tool to Assist Developers in Fixing Bugs},
  shorttitle = {{{BugFix}}},
  booktitle = {2009 {{IEEE}} 17th {{International Conference}} on {{Program Comprehension}}},
  author = {Jeffrey, Dennis and Feng, Min and Gupta, Neelam and Gupta, Rajiv},
  year = {2009},
  month = may,
  pages = {70--79},
  issn = {1092-8138},
  doi = {10.1109/ICPC.2009.5090029},
  url = {https://ieeexplore.ieee.org/document/5090029},
  urldate = {2023-11-14},
  abstract = {We present a tool called BugFix that can assist developers in fixing program bugs. Our tool automatically analyzes the debugging situation at a statement and reports a prioritized list of relevant bug-fix suggestions that are likely to guide the developer to an appropriate fix at that statement. BugFix incorporates ideas from machine learning to automatically learn from new debugging situations and bug fixes over time. This enables more effective prediction of the most relevant bug-fix suggestions for newly-encountered debugging situations. The tool takes into account the static structure of a statement, the dynamic values used at that statement by both passing and failing runs, and the interesting value mapping pairs [17] associated with that statement. We present a case study illustrating the efficacy of BugFix in helping developers to fix bugs.},
  annotation = {53 citations (Crossref) [2023-11-13]},
  file = {C:\Users\Andrew\Zotero\storage\ZNMVUZVU\Jeffrey et al_2009_BugFix.pdf}
}

@inproceedings{jessupUsingEyeTrackingData2021,
  title = {Using {{Eye-Tracking Data}} to {{Compare Differences}} in {{Code Comprehension}} and {{Code Perceptions}} between {{Expert}} and {{Novice Programmers}}},
  booktitle = {Hawaii {{International Conference}} on {{System Sciences}}},
  author = {Jessup, Sarah and Willis, Sasha M. and Alarcon, Gene and Lee, Michael},
  year = {2021},
  doi = {10.24251/HICSS.2021.013},
  url = {http://hdl.handle.net/10125/70624},
  urldate = {2023-06-05},
  abstract = {Previous research has examined how eye-tracking metrics can serve as a proxy for directly measuring the amount of cognitive effort and processing required for comprehending computer code. We conducted a pilot study comprising expert (n = 10) and novice (n = 10) computer programmers to examine group differences in code comprehension abilities and perceptions. Programmers were asked to read two pieces of computer code, rate the code on various attributes, and then describe what the code does. Results indicate that experts and novices significantly differ in terms of their fixation counts made during the task, such that experts had more fixations than novices. This was counter to our hypothesis that experts would have fewer fixations than novices. We found no evidence that experts and novices differed in their average fixation durations, trustworthiness and performance perceptions, or willingness to reuse the code.},
  keywords = {Finished,Student/Academia},
  annotation = {1 citations (Crossref) [2023-06-05]},
  file = {C:\Users\Andrew\Zotero\storage\MWIZVYX3\Jessup et al_2021_Using Eye-Tracking Data to Compare Differences in Code Comprehension and Code.pdf}
}

@misc{johnzorabedianVeracodeSurveyResearch,
  title = {Veracode {{Survey Research Identifies Cybersecurity Skills Gap Causes}} and {{Cures}}},
  author = {{John Zorabedian}},
  journal = {Veracode},
  url = {https://www.veracode.com/blog/security-news/veracode-survey-research-identifies-cybersecurity-skills-gap-causes-and-cures},
  urldate = {2023-07-12},
  abstract = {The shortage of cybersecurity professionals is on pace to reach 1.5 million empty positions globally by 2020, according to Frost \& Sullivan. Yet, as the digital economy relies on rapid innovation in software, the growing demand for developers with security skills is also dangerously outpacing supply.},
  langid = {english},
  keywords = {Finished,Industry},
  file = {C:\Users\Andrew\Zotero\storage\LU6MC8G3\veracode-survey-research-identifies-cybersecurity-skills-gap-causes-and-cures.html}
}

@book{jointtaskforceoncomputingcurriculaassociationforcomputingmachineryacmandieeecomputersocietyComputerScienceCurricula2013,
  title = {Computer {{Science Curricula}} 2013: {{Curriculum Guidelines}} for {{Undergraduate Degree Programs}} in {{Computer Science}}},
  shorttitle = {Computer {{Science Curricula}} 2013},
  author = {{Joint Task Force on Computing Curricula, Association for Computing Machinery (ACM) {and} IEEE Computer Society}},
  year = {2013},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  isbn = {978-1-4503-2309-3},
  file = {C:\Users\Andrew\Zotero\storage\L6DGZ8GD\Joint Task Force on Computing Curricula, Association for Computing Machinery (ACM) and IEEE Computer Society_2013_Computer Science Curricula 2013.pdf}
}

@article{jonesCoreCyberDefenseKnowledge2018,
  title = {The {{Core Cyber-Defense Knowledge}}, {{Skills}}, and {{Abilities That Cybersecurity Students Should Learn}} in {{School}}: {{Results}} from {{Interviews}} with {{Cybersecurity Professionals}}},
  shorttitle = {The {{Core Cyber-Defense Knowledge}}, {{Skills}}, and {{Abilities That Cybersecurity Students Should Learn}} in {{School}}},
  author = {Jones, Keith S. and Namin, Akbar Siami and Armstrong, Miriam E.},
  year = {2018},
  month = sep,
  journal = {ACM Transactions on Computing Education},
  volume = {18},
  number = {3},
  pages = {1--12},
  issn = {1946-6226},
  doi = {10.1145/3152893},
  url = {https://dl.acm.org/doi/10.1145/3152893},
  urldate = {2024-09-09},
  abstract = {Our cybersecurity workforce needs surpass our ability to meet them. These needs could be mitigated by developing relevant curricula that prioritize the knowledge, skills, and abilities (KSAs) most important to cybersecurity jobs. To identify the KSAs needed for performing cybersecurity jobs, we administered survey interviews to 44 cyber professionals at the premier hacker conferences Black Hat 2016 and DEF CON 24. Questions concerned 32 KSAs related to cyber defense. Participants rated how important each KSA was to their job and indicated where they had learned that KSA. Fifteen of these KSAs were rated as being of higher-than-neutral importance. Participants also answered open-ended questions meant to uncover additional KSAs that are important to cyber-defense work. Overall, the data suggest that KSAs related to networks, vulnerabilities, programming, and interpersonal communication should be prioritized in cybersecurity curricula.},
  langid = {english},
  annotation = {40 citations (Crossref) [2024-09-09]},
  file = {C:\Users\Andrew\Zotero\storage\67HMFUKJ\Jones et al_2018_The Core Cyber-Defense Knowledge, Skills, and Abilities That Cybersecurity.pdf}
}

@inproceedings{junzhuInteractiveSupportSecure2013,
  title = {Interactive Support for Secure Programming Education},
  booktitle = {Proceeding of the 44th {{ACM}} Technical Symposium on {{Computer}} Science Education},
  author = {{Jun Zhu} and {Heather Richter Lipford} and {Bill Chu}},
  year = {2013},
  month = mar,
  series = {{{SIGCSE}} '13},
  pages = {687--692},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2445196.2445396},
  url = {https://dl.acm.org/doi/10.1145/2445196.2445396},
  urldate = {2023-07-17},
  abstract = {Software flaws are a root cause of many of today's information security vulnerabilities. Current curricula emphasis on traditional information security issues does not address this root cause. We propose educating students on secure programming techniques through interactive tool support in the Integrated Development Environment (IDE). We believe this approach can complement other curricula efforts by teaching and providing continuous reinforcement of practices throughout programming tasks. In this paper, we evaluate our prototype tool, ASIDE, which provides instant security warnings, detailed explanations of vulnerabilities, and code generation. We report the results of an observational study on 20 students from an advanced Web programming course. The results provide early evidence that our tool could potentially help students learn about and practice secure programming in the context of their programming assignments.},
  isbn = {978-1-4503-1868-6},
  keywords = {IDE,secure programming,security education},
  annotation = {19 citations (Crossref) [2023-07-17]},
  file = {C:\Users\Andrew\Zotero\storage\QQ2PDV63\Zhu et al_2013_Interactive support for secure programming education.pdf}
}

@article{kennetha.williamsTeachingSecureCoding2014,
  title = {Teaching Secure Coding for Beginning Programmers},
  author = {{Kenneth A. Williams} and {Xiaohong Yuan} and {Huiming Yu} and {Kelvin Bryant}},
  year = {2014},
  month = may,
  journal = {Journal of Computing Sciences in Colleges},
  volume = {29},
  number = {5},
  pages = {91--99},
  issn = {1937-4771},
  abstract = {The recent addition of the Information Assurance and Security (IAS) Knowledge Area (KA) to the ACM/IEEE draft Computer Science Curricula 2013 indicates the importance of preparing computer science graduates to design and implement secure software. We have identified material in the Information Assurance and Security/Defensive Programming KA that can easily be taught to beginning programmers. In this paper, we recommended secure coding topics based on our experience in teaching secure coding in CS0/CS1 courses. We discussed how these topics can be mapped to IAS Knowledge Areas, as well as the unique challenges of teaching secure coding to beginning programmers. We also point out some behaviors of beginning programmers leading to insecure programs that may need the instructor's attention. The information reported in this paper will help other computer science educators to incorporate secure coding into their CS0/CS1 courses. Our future work includes designing more assessment tools to evaluate beginning programmer's learning of secure coding.},
  keywords = {Student/Academia},
  file = {C:\Users\Andrew\Zotero\storage\CG962JKJ\Williams et al_2014_Teaching secure coding for beginning programmers.pdf}
}

@article{kulenovicSurveyStaticCode2014,
  title = {A Survey of Static Code Analysis Methods for Security Vulnerabilities Detection},
  author = {Kulenovic, Melina and Donko, Dzenana},
  year = {2014},
  month = may,
  journal = {2014 37th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)},
  pages = {1381--1386},
  publisher = {IEEE},
  address = {Opatija, Croatia},
  doi = {10.1109/MIPRO.2014.6859783},
  url = {http://ieeexplore.ieee.org/document/6859783/},
  urldate = {2023-06-21},
  abstract = {Software security is becoming highly important for universal acceptance of applications for many kinds of transactions. Automated code analyzers can be utilized to detect security vulnerabilities during the development phase. This paper is aimed to provide a survey on Static code analysis and how it can be used to detect security vulnerabilities. The most recent findings and publications are summarized and presented in this paper. This paper provides an overview of the gains, flows and algorithms of static code analyzers. It can be considered a stepping stone for further research in this domain.},
  isbn = {9789532330779 9789532330816},
  keywords = {Vulnerability Research},
  annotation = {6 citations (Crossref) [2023-06-23]},
  file = {C:\Users\Andrew\Zotero\storage\EYPCZ86M\Kulenovic_Donko_2014_A survey of static code analysis methods for security vulnerabilities detection.pdf}
}

@inproceedings{lamIdentifyingGapsSecure2022,
  title = {Identifying {{Gaps}} in the {{Secure Programming Knowledge}} and {{Skills}} of {{Students}}},
  booktitle = {Proceedings of the 53rd {{ACM Technical Symposium}} on {{Computer Science Education}} - {{Volume}} 1},
  author = {Lam, Jessica and Fang, Elias and Almansoori, Majed and Chatterjee, Rahul and Soosai Raj, Adalbert Gerald},
  year = {2022},
  month = feb,
  series = {{{SIGCSE}} 2022},
  volume = {1},
  pages = {703--709},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3478431.3499391},
  url = {https://dl.acm.org/doi/10.1145/3478431.3499391},
  urldate = {2024-11-15},
  abstract = {Often, security topics are only taught in advanced computer science (CS) courses. However, most US R1 universities do not require students to take these courses to complete an undergraduate CS degree. As a result, students can graduate without learning about computer security and secure programming practices. To gauge students' knowledge and skills of secure programming, we conducted a coding interview with 21 students from two R1 universities in the United States. All the students in our study had at least taken Computer Systems or an equivalent course. We then analyzed the students' approach to safe programming practices, such as avoiding unsafe functions like gets and strcpy, and basic security knowledge, such as writing code that assumes user inputs can be malicious. Our results suggest that students lack the key fundamental skills to write secure programs. For example, students rarely pay attention to details, such as compiler warnings, and often do not read programming language documentation with care. Moreover, some students' understanding of memory layout is cursory, which is crucial for writing secure programs. We also found that some students are struggling with even the basics of C programming, even though it is the main language taught in Computer Systems courses.},
  isbn = {978-1-4503-9070-5},
  file = {C:\Users\Andrew\Zotero\storage\XIW4C24Z\Lam et al. - 2022 - Identifying Gaps in the Secure Programming Knowledge and Skills of Students.pdf}
}

@article{lenarduzziCriticalComparisonSix,
  title = {A {{Critical Comparison}} on {{Six Static Analysis Tools}}: {{Detection}}, {{Agreement}}, and {{Precision}}},
  author = {Lenarduzzi, Valentina and Pecorelli, Fabiano and Saarimaki, Nyyti and Lujan, Savanna and Palomba, Fabio},
  abstract = {Background. Developers use Static Analysis Tools (SATs) to control for potential quality issues in source code, including defects and technical debt. Tool vendors have devised quite a number of tools, which makes it harder for practitioners to select the most suitable one for their needs. To better support developers, researchers have been conducting several studies on SATs to favor the understanding of their actual capabilities. Aims. Despite the work done so far, there is still a lack of knowledge regarding (1) what is their agreement, and (2) what is the precision of their recommendations. We aim at bridging this gap by proposing a large-scale comparison of six popular SATs for Java projects: Better Code Hub, CheckStyle, Coverity Scan, FindBugs, PMD, and SonarQube. Method. We analyze 47 Java projects applying 6 SATs. To assess their agreement, we compared them by manually analyzing - at line- and class-level - whether they identify the same issues. Finally, we evaluate the precision of the tools against a manually-defined ground truth. Results. The key results show little to no agreement among the tools and a low degree of precision. Conclusions. Our study provides the first overview on the agreement among different tools as well as an extensive analysis of their precision that can be used by researchers, practitioners, and tool vendors to map the current capabilities of the tools and envision possible improvements.},
  langid = {english},
  keywords = {Vulnerability Research},
  file = {C:\Users\Andrew\Zotero\storage\TPLIB6GT\Lenarduzzi et al. - A Critical Comparison on Six Static Analysis Tools.pdf}
}

@misc{liAttentionAllYou2024a,
  title = {Attention {{Is All You Need}} for {{LLM-based Code Vulnerability Localization}}},
  author = {Li, Yue and Li, Xiao and Wu, Hao and Zhang, Yue and Cheng, Xiuzhen and Zhong, Sheng and Xu, Fengyuan},
  year = {2024},
  month = oct,
  number = {arXiv:2410.15288},
  eprint = {2410.15288},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.15288},
  url = {http://arxiv.org/abs/2410.15288},
  urldate = {2024-11-15},
  abstract = {The rapid expansion of software systems and the growing number of reported vulnerabilities have emphasized the importance of accurately identifying vulnerable code segments. Traditional methods for vulnerability localization, such as manual code audits or rule-based tools, are often time-consuming and limited in scope, typically focusing on specific programming languages or types of vulnerabilities. In recent years, the introduction of large language models (LLMs) such as GPT and LLaMA has opened new possibilities for automating vulnerability detection. However, while LLMs show promise in this area, they face challenges, particularly in maintaining accuracy over longer code contexts. This paper introduces LOVA, a novel framework leveraging the self-attention mechanisms inherent in LLMs to enhance vulnerability localization. Our key insight is that self-attention mechanisms assign varying importance to different parts of the input, making it possible to track how much attention the model focuses on specific lines of code. In the context of vulnerability localization, the hypothesis is that vulnerable lines of code will naturally attract higher attention weights because they have a greater influence on the model's output. By systematically tracking changes in attention weights and focusing on specific lines of code, LOVA improves the precision of identifying vulnerable lines across various programming languages. Through rigorous experimentation and evaluation, we demonstrate that LOVA significantly outperforms existing LLM-based approaches, achieving up to a 5.3x improvement in F1-scores. LOVA also demonstrated strong scalability, with up to a 14.6x improvement in smart contract vulnerability localization across languages like C, Python, Java, and Solidity. Its robustness was proven through consistent performance across different LLM architectures.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Vulnerability Research},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\G522ATCQ\\Li et al. - 2024 - Attention Is All You Need for LLM-based Code Vulnerability Localization.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\4378BAI4\\2410.html}
}

@inproceedings{liuTraditionalTeachingLarge2024,
  title = {Beyond {{Traditional Teaching}}: {{Large Language Models}} as {{Simulated Teaching Assistants}} in {{Computer Science}}},
  shorttitle = {Beyond {{Traditional Teaching}}},
  booktitle = {Proceedings of the 55th {{ACM Technical Symposium}} on {{Computer Science Education V}}. 1},
  author = {Liu, Mengqi and M'Hiri, Faten},
  year = {2024},
  month = mar,
  series = {{{SIGCSE}} 2024},
  pages = {743--749},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3626252.3630789},
  url = {https://dl.acm.org/doi/10.1145/3626252.3630789},
  urldate = {2024-11-12},
  abstract = {As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.},
  isbn = {9798400704239},
  file = {C:\Users\Andrew\Zotero\storage\CU7KFGSW\Liu and M'Hiri - 2024 - Beyond Traditional Teaching Large Language Models as Simulated Teaching Assistants in Computer Scie.pdf}
}

@article{liVulDeeLocatorDeepLearningbased2022,
  title = {{{VulDeeLocator}}: {{A Deep Learning-based Fine-grained Vulnerability Detector}}},
  shorttitle = {{{VulDeeLocator}}},
  author = {Li, Zhen and Zou, Deqing and Xu, Shouhuai and Chen, Zhaoxuan and Zhu, Yawei and Jin, Hai},
  year = {2022},
  month = jul,
  journal = {IEEE Transactions on Dependable and Secure Computing},
  volume = {19},
  number = {4},
  eprint = {2001.02350},
  primaryclass = {cs},
  pages = {2821--2837},
  issn = {1545-5971, 1941-0018, 2160-9209},
  doi = {10.1109/TDSC.2021.3076142},
  url = {http://arxiv.org/abs/2001.02350},
  urldate = {2023-03-10},
  abstract = {Automatically detecting software vulnerabilities is an important problem that has attracted much attention from the academic research community. However, existing vulnerability detectors still cannot achieve the vulnerability detection capability and the locating precision that would warrant their adoption for real-world use. In this paper, we present a vulnerability detector that can simultaneously achieve a high detection capability and a high locating precision, dubbed Vulnerability Deep learning-based Locator (VulDeeLocator). In the course of designing VulDeeLocator, we encounter difficulties including how to accommodate semantic relations between the definitions of types as well as macros and their uses across files, how to accommodate accurate control flows and variable define-use relations, and how to achieve high locating precision. We solve these difficulties by using two innovative ideas: (i) leveraging intermediate code to accommodate extra semantic information, and (ii) using the notion of granularity refinement to pin down locations of vulnerabilities. When applied to 200 files randomly selected from three real-world software products, VulDeeLocator detects 18 confirmed vulnerabilities (i.e., true-positives). Among them, 16 vulnerabilities correspond to known vulnerabilities; the other two are not reported in the National Vulnerability Database (NVD) but have been "silently" patched by the vendor of Libav when releasing newer versions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Vulnerability Research},
  annotation = {15 citations (Crossref) [2023-03-10]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\Y2HAQTWU\\Li et al_2022_VulDeeLocator.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\YQNKA9KG\\2001.html}
}

@article{liVulnerabilitiesMappingBased2020,
  title = {Vulnerabilities {{Mapping}} Based on {{OWASP-SANS}}: {{A Survey}} for {{Static Application Security Testing}} ({{SAST}})},
  shorttitle = {Vulnerabilities {{Mapping}} Based on {{OWASP-SANS}}},
  author = {Li, Jinfeng},
  year = {2020},
  month = jul,
  journal = {Annals of Emerging Technologies in Computing},
  volume = {4},
  number = {3},
  pages = {1--8},
  issn = {2516-029X, 2516-0281},
  doi = {10.33166/AETiC.2020.03.001},
  url = {http://aetic.theiaer.org/archive/v4/v4n3/p1.html},
  urldate = {2023-06-21},
  abstract = {The delivery of a framework in place for secure application development is of real value for application development teams to integrate security into their development life cycle, especially when a mobile or web application moves past the scanning stage and focuses increasingly on the remediation or mitigation phase based on static application security testing (SAST). For the first time, to the author's knowledge, the industry-standard Open Web Application Security Project (OWASP) top 10 vulnerabilities and CWE/SANS top 25 most dangerous software errors are synced up in a matrix with Checkmarx vulnerability queries, producing an application security framework that helps development teams review and address code vulnerabilities, minimise false positives discovered in static scans and penetration tests, targeting an increased accuracy of the findings. A case study is conducted for vulnerabilities scanning of a proof-of-concept mobile malware detection app. Mapping the OWASP/SANS with Checkmarx vulnerabilities queries, flaws and vulnerabilities are demonstrated to be mitigated with improved efficiency.},
  langid = {english},
  keywords = {Vulnerability Research},
  annotation = {33 citations (Crossref) [2023-06-23]},
  file = {C:\Users\Andrew\Zotero\storage\J792XJGM\Li_2020_Vulnerabilities Mapping based on OWASP-SANS.pdf}
}

@misc{MachineLearningSoftware2023,
  title = {Machine {{Learning}} for {{Software Engineering}}},
  year = {2023},
  month = apr,
  url = {https://github.com/saltudelft/ml4se},
  urldate = {2023-04-19},
  abstract = {A curated list of papers, theses, datasets, and tools related to the application of Machine Learning for Software Engineering},
  howpublished = {Software Analytics Lab},
  keywords = {ai4code,code,datasets,deep-learning,machine-learning,ml4code,ml4se,papers,research,software-engineering,theses,tools,tudelft}
}

@misc{MachineLearningSource,
  title = {Machine {{Learning}} for {{Source Code Vulnerability Detection}}: {{What Works}} and {{What Isn}}'t {{There Yet}}},
  url = {https://www.computer.org/csdl/magazine/sp/2022/05/09859261/1FUYCoA21q0},
  urldate = {2023-02-01},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\JLMN5AEQ\\Machine Learning for Source Code Vulnerability Detection.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\MEW79BXH\\1FUYCoA21q0.html}
}

@article{malikAnalysisCodeVulnerabilities2022,
  title = {Analysis of {{Code Vulnerabilities}} in {{Repositories}} of {{GitHub}} and {{RosettaCode}}: {{A Comparative Study}}},
  shorttitle = {Analysis of {{Code Vulnerabilities}} in {{Repositories}} of {{GitHub}} and {{RosettaCode}}},
  author = {Malik, Abdul and Malik, Abdul and Imran, Imran},
  year = {2022},
  month = jun,
  journal = {International Journal of Innovations in Science and Technology},
  volume = {4},
  pages = {499--511},
  doi = {10.33411/IJIST/2022040219},
  abstract = {Open-source code hosted online at programming portals is present in 99\% of commercial software and is common practice among developers for rapid prototyping and cost-effective development. However, research reports the presence of vulnerabilities, which result in catastrophic security compromise, and the individual, organization, and even national secrecy are all victims of this circumstance. One of the frustrating aspects of vulnerabilities is that vulnerabilities manifest themselves in hidden ways that software developers are unaware of. One of the most critical tasks in ensuring software security is vulnerability detection, which jeopardizes core security concepts like integrity, authenticity, and availability. This study aims to explore security-related vulnerabilities in programming languages such as C, C++, and Java and present the disparities between them hosted at popular code repositories. To attain this purpose, 708 programs were examined by severity-based guidelines. A total of 1371 vulnerable codes were identified, of which 327 in C, 51 in C++, and 993 in Java. Statistical analysis also indicated a substantial difference between them, as there is ample evidence that the Kruskal-Wallis H-test p-value (.000) is below the 0.05 significance level. The Mann-Whitney Test mean rank for GitHub (Mean-rank=676.05) and Rosettacode (Mean-rank=608.64) are also different. The novelty of this article is to identify security vulnerabilities and grasp the nature severity of vulnerability in popular code repositories. This study eventually manifests a guideline for choosing a secure programming language as a successful testing technique that targets vulnerabilities more liable to breaching security.},
  annotation = {1 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\PX324LK2\Malik et al_2022_Analysis of Code Vulnerabilities in Repositories of GitHub and RosettaCode.pdf}
}

@inproceedings{meissnerMEITREXGamifiedAdaptive2024,
  title = {{{MEITREX}} - {{Gamified}} and {{Adaptive Intelligent Tutoring}} in {{Software Engineering Education}}},
  booktitle = {Proceedings of the 2024 {{IEEE}}/{{ACM}} 46th {{International Conference}} on {{Software Engineering}}: {{Companion Proceedings}}},
  author = {Mei{\ss}ner, Niklas},
  year = {2024},
  month = may,
  series = {{{ICSE-Companion}} '24},
  pages = {198--200},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3639478.3639804},
  url = {https://dl.acm.org/doi/10.1145/3639478.3639804},
  urldate = {2024-11-21},
  abstract = {Nowadays, learning management systems (LMSs) are established tools in higher education, especially in the domain of software engineering (SE). However, the potential of such educational technologies has not been fully exploited, as student performance in SE education is still strongly dependent on feedback from time-constrained lecturers and tutors. Moreover, current LMSs are not designed for SE courses, as external SE tools are required to fulfill the requirements of lecturers such as programming and UML modeling features. Evolving these LMSs in the direction of intelligent tutoring could assist students in receiving automatic, individual feedback from the LMSs on their learning performance at any time. Also, gamified learning elements can serve to motivate students to engage with SE materials. Therefore, this paper presents an approach combining learning analytics, feedback, and interactive learning such as gamification in one LMS designed for SE education. The system could thus address diverse students with different backgrounds and motivational aspects and provide appropriate individual support to ensure effective SE education.},
  isbn = {9798400705021},
  file = {C:\Users\Andrew\Zotero\storage\HEFXIWFZ\MeiÃner - 2024 - MEITREX - Gamified and Adaptive Intelligent Tutoring in Software Engineering Education.pdf}
}

@article{meliHowBadCan2019,
  title = {How {{Bad Can It Git}}? {{Characterizing Secret Leakage}} in {{Public GitHub Repositories}}},
  shorttitle = {How {{Bad Can It Git}}?},
  author = {Meli, Michael and McNiece, Matthew R. and Reaves, Bradley},
  year = {2019},
  journal = {Proceedings 2019 Network and Distributed System Security Symposium},
  publisher = {Internet Society},
  address = {San Diego, CA},
  doi = {10.14722/ndss.2019.23418},
  url = {https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_04B-3_Meli_paper.pdf},
  urldate = {2022-12-21},
  abstract = {GitHub and similar platforms have made public collaborative development of software commonplace. However, a problem arises when this public code must manage authentication secrets, such as API keys or cryptographic secrets. These secrets must be kept private for security, yet common development practices like adding these secrets to code make accidental leakage frequent. In this paper, we present the first large-scale and longitudinal analysis of secret leakage on GitHub. We examine billions of files collected using two complementary approaches: a nearly six-month scan of real-time public GitHub commits and a public snapshot covering 13\% of open-source repositories. We focus on private key files and 11 high-impact platforms with distinctive API key formats. This focus allows us to develop conservative detection techniques that we manually and automatically evaluate to ensure accurate results. We find that not only is secret leakage pervasive --- affecting over 100,000 repositories --- but that thousands of new, unique secrets are leaked every day. We also use our data to explore possible root causes of leakage and to evaluate potential mitigation strategies. This work shows that secret leakage on public repository platforms is rampant and far from a solved problem, placing developers and services at persistent risk of compromise and abuse.},
  isbn = {9781891562556},
  langid = {english},
  keywords = {Industry,Student/Academia},
  annotation = {22 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\CALJJSRA\Meli et al_2019_How Bad Can It Git.pdf}
}

@inproceedings{mengSecureCodingPractices2018,
  title = {Secure Coding Practices in {{Java}}: Challenges and Vulnerabilities},
  shorttitle = {Secure Coding Practices in {{Java}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Software Engineering}}},
  author = {Meng, Na and Nagy, Stefan and Yao, Danfeng (Daphne) and Zhuang, Wenjie and Argoty, Gustavo Arango},
  year = {2018},
  month = may,
  series = {{{ICSE}} '18},
  pages = {372--383},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3180155.3180201},
  url = {https://doi.org/10.1145/3180155.3180201},
  urldate = {2022-09-18},
  abstract = {The Java platform and its third-party libraries provide useful features to facilitate secure coding. However, misusing them can cost developers time and effort, as well as introduce security vulnerabilities in software. We conducted an empirical study on StackOverflow posts, aiming to understand developers' concerns on Java secure coding, their programming obstacles, and insecure coding practices. We observed a wide adoption of the authentication and authorization features provided by Spring Security---a third-party framework designed to secure enterprise applications. We found that programming challenges are usually related to APIs or libraries, including the complicated cross-language data handling of cryptography APIs, and the complex Java-based or XML-based approaches to configure Spring Security. In addition, we reported multiple security vulnerabilities in the suggested code of accepted answers on the StackOverfow forum. The vulnerabilities included disabling the default protection against Cross-Site Request Forgery (CSRF) attacks, breaking SSL/TLS security through bypassing certificate validation, and using insecure cryptographic hash functions. Our findings reveal the insufficiency of secure coding assistance and documentation, as well as the huge gap between security theory and coding practices.},
  isbn = {978-1-4503-5638-1},
  keywords = {authentication,authorization,certificate validation,cryptographic hash functions,cryptography,CSRF,Finished,secure coding,spring security,SSL/TLS,stackOverflow},
  annotation = {66 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\VE8HY4QW\Meng et al_2018_Secure coding practices in Java.pdf}
}

@article{MicrosoftDigitalDefense,
  title = {Microsoft {{Digital Defense Report}} 2022},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\XW6G9YHS\Microsoft Digital Defense Report 2022.pdf}
}

@inproceedings{mirskyVulCheckerGraphbasedVulnerability2023,
  title = {\{\vphantom\}{{VulChecker}}\vphantom\{\}: {{Graph-based Vulnerability Localization}} in {{Source Code}}},
  shorttitle = {\{\vphantom\}{{VulChecker}}\vphantom\{\}},
  booktitle = {32nd {{USENIX Security Symposium}} ({{USENIX Security}} 23)},
  author = {Mirsky, Yisroel and Macon, George and Brown, Michael and Yagemann, Carter and Pruett, Matthew and Downing, Evan and Mertoguno, Sukarno and Lee, Wenke},
  year = {2023},
  pages = {6557--6574},
  url = {https://www.usenix.org/conference/usenixsecurity23/presentation/mirsky},
  urldate = {2023-08-30},
  isbn = {978-1-939133-37-3},
  langid = {english},
  keywords = {Vulnerability Research},
  file = {C:\Users\Andrew\Zotero\storage\K8R9XRMV\Mirsky et al_2023_ VulChecker .pdf}
}

@misc{mohamedamineferragGenerativeAILarge2024,
  title = {Generative {{AI}} and {{Large Language Models}} for {{Cyber Security}}: {{All Insights You Need}}},
  shorttitle = {Generative {{AI}} and {{Large Language Models}} for {{Cyber Security}}},
  author = {{Mohamed Amine Ferrag} and {Fatima Alwahedi} and {Ammar Battah} and {Bilel Cherif} and {Abdechakour Mechri} and {Norbert Tihanyi}},
  year = {2024},
  month = may,
  number = {arXiv:2405.12750},
  eprint = {2405.12750},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.12750},
  url = {http://arxiv.org/abs/2405.12750},
  urldate = {2024-05-31},
  abstract = {This paper provides a comprehensive review of the future of cybersecurity through Generative AI and Large Language Models (LLMs). We explore LLM applications across various domains, including hardware design security, intrusion detection, software engineering, design verification, cyber threat intelligence, malware detection, and phishing detection. We present an overview of LLM evolution and its current state, focusing on advancements in models such as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends to LLM vulnerabilities, such as prompt injection, insecure output handling, data poisoning, DDoS attacks, and adversarial instructions. We delve into mitigation strategies to protect these models, providing a comprehensive look at potential attack scenarios and prevention techniques. Furthermore, we evaluate the performance of 42 LLM models in cybersecurity knowledge and hardware security, highlighting their strengths and weaknesses. We thoroughly evaluate cybersecurity datasets for LLM training and testing, covering the lifecycle from data creation to usage and identifying gaps for future research. In addition, we review new strategies for leveraging LLMs, including techniques like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank Adapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim to enhance real-time cybersecurity defenses and improve the sophistication of LLM applications in threat detection and response. Our paper provides a foundational understanding and strategic direction for integrating LLMs into future cybersecurity frameworks, emphasizing innovation and robust model deployment to safeguard against evolving cyber threats.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\23U42DJJ\\Ferrag et al_2024_Generative AI and Large Language Models for Cyber Security.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\TLMGABM5\\2405.html}
}

@inproceedings{mohammadtahaeiSurveyDeveloperCentredSecurity2019,
  title = {A {{Survey}} on {{Developer-Centred Security}}},
  booktitle = {2019 {{IEEE European Symposium}} on {{Security}} and {{Privacy Workshops}} ({{EuroS}}\&{{PW}})},
  author = {{Mohammad Tahaei} and {Kami Vaniea}},
  year = {2019},
  month = jun,
  pages = {129--138},
  doi = {10.1109/EuroSPW.2019.00021},
  url = {https://ieeexplore.ieee.org/document/8802434},
  urldate = {2024-07-26},
  abstract = {Software developers are key players in the security ecosystem as they produce code that runs on millions of devices. Yet we continue to see insecure code being developed and deployed on a regular basis despite the existence of support infrastructures, tools, and research into common errors. This work provides a systematised overview of the relatively new field of Developer-Centred Security which aims to understand the context in which developers produce security-relevant code as well as provide tools and processes that that better support both developers and secure code production. We report here on a systematic literature review of 49 publications on security studies with software developer participants. We provide an overview of both the types of methodologies currently being used as well as the current research in the area. Finally, we also provide recommendations for future work in Developer-Centred Security.},
  keywords = {Computer Security,Cryptography,Developers,Finished,Human Computer Interaction,Human Factors,Industry,Interviews,Privacy,Software,Software Development,Survey,Systematic Literature Review,Task analysis,Tools,Usable Security and Privacy},
  annotation = {45 citations (Crossref) [2024-07-26]},
  file = {C:\Users\Andrew\Zotero\storage\5VQCU8DI\Tahaei_Vaniea_2019_A Survey on Developer-Centred Security.pdf}
}

@misc{mouConvolutionalNeuralNetworks2015,
  title = {Convolutional {{Neural Networks}} over {{Tree Structures}} for {{Programming Language Processing}}},
  author = {Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi},
  year = {2015},
  month = dec,
  number = {arXiv:1409.5718},
  eprint = {1409.5718},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1409.5718},
  url = {http://arxiv.org/abs/1409.5718},
  urldate = {2024-09-08},
  abstract = {Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However, different from a natural language sentence, a program contains rich, explicit, and complicated structural information. Hence, traditional NLP models may be inappropriate for programs. In this paper, we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing, in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Software Engineering},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\3JNNW5EC\\Mou et al_2015_Convolutional Neural Networks over Tree Structures for Programming Language.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\82F3KUIS\\1409.html}
}

@misc{NISTSoftwareAssurance,
  title = {{{NIST Software Assurance Reference Dataset}}},
  journal = {NIST Software Assurance Reference Dataset},
  url = {https://samate.nist.gov/SARD},
  urldate = {2023-02-22},
  abstract = {The Software Assurance Reference Dataset (SARD) is a publicly accessible collection of over 450,000 test cases in different programming languages, covering dozens of different classes of weaknesses, such as those in the Common Weakness Enumeration (CWE)},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\KKLDXMMU\SARD.html}
}

@article{nugrohoStudyVulnerabilityIdentifiers2022,
  title = {A {{Study}} of {{Vulnerability Identifiers}} in {{Code Comments}}: {{Source}}, {{Purpose}}, and {{Severity}}},
  shorttitle = {A {{Study}} of {{Vulnerability Identifiers}} in {{Code Comments}}},
  author = {Nugroho, Yusuf Sulistyo and Gunawan, Dedi and Putri, Devi Afriyantari Puspa and Islam, Syful and Alhefdhi, Abdulaziz},
  year = {2022},
  journal = {Journal of Communications Software and Systems},
  volume = {18},
  number = {2},
  pages = {165--174},
  issn = {18456421, 18466079},
  doi = {10.24138/jcomss-2021-0124},
  url = {https://jcoms.fesb.unist.hr/10.24138/jcomss-2021-0124/},
  urldate = {2024-11-13},
  abstract = {Software vulnerability is one of the weaknesses in computer security that challenges developers to rectify. Software maintainers rely on code comments to maintain their source code, including fixing vulnerability issues. To facilitate understanding the security issues in the related code, vulnerability identifiers are commonly included in code comments. However, not all vulnerability-related code comments describe clearly the purposes of the inclusion of the identifiers. Based on this evidence, we investigate the importance of vulnerability identifiers contained in source code comments, which is the novelty of this paper. We performed a study of 1,491 code comments that refer to vulnerability identifiers to define their categories. We then applied a mixed-method approach to classifying the types of the related repository and code, the rationale of identifier references, and the severity level of vulnerabilities in the code. The results indicate that vulnerability identifiers in code comments are useful to notify security issues for the related source code, and our study widens up chances for future work to further investigate these problems.},
  langid = {english},
  keywords = {Vulnerability Research},
  file = {C:\Users\Andrew\Zotero\storage\XT6IWVKX\Nugroho et al. - 2022 - A Study of Vulnerability Identifiers in Code Comments Source, Purpose, and Severity.pdf}
}

@misc{NVDCVSSSeverity,
  title = {{{NVD}} - {{CVSS Severity Distribution Over Time}}},
  url = {https://nvd.nist.gov/general/visualizations/vulnerability-visualizations/cvss-severity-distribution-over-time},
  urldate = {2023-04-17},
  file = {C:\Users\Andrew\Zotero\storage\ZFU78S4I\cvss-severity-distribution-over-time.html}
}

@misc{NVDHome,
  title = {{{NVD}} - {{Home}}},
  url = {https://nvd.nist.gov/},
  urldate = {2023-02-22}
}

@inproceedings{pangPredictingVulnerableSoftware2015,
  title = {Predicting {{Vulnerable Software Components}} through {{N-Gram Analysis}} and {{Statistical Feature Selection}}},
  booktitle = {2015 {{IEEE}} 14th {{International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  author = {Pang, Yulei and Xue, Xiaozhen and Namin, Akbar Siami},
  year = {2015},
  month = dec,
  pages = {543--548},
  doi = {10.1109/ICMLA.2015.99},
  url = {https://ieeexplore.ieee.org/document/7424372},
  urldate = {2024-09-08},
  abstract = {Vulnerabilities need to be detected and removed from software. Although previous studies demonstrated the usefulness of employing prediction techniques in deciding about vulnerabilities of software components, the accuracy and improvement of effectiveness of these prediction techniques is still a grand challenging research question. This paper proposes a hybrid technique based on combining N-gram analysis and feature selection algorithms for predicting vulnerable software components where features are defined as continuous sequences of token in source code files, i.e., Java class file. Machine learning-based feature selection algorithms are then employed to reduce the feature and search space. We evaluated the proposed technique based on some Java Android applications, and the results demonstrated that the proposed technique could predict vulnerable classes, i.e., software components, with high precision, accuracy and recall.},
  keywords = {Feature extraction,Feature selection,Java,Measurement,N-gram,Prediction algorithms,Predictive models,Software,Support vector machines,Vulnerability prediction,Wilcoxon test},
  annotation = {49 citations (Crossref) [2024-09-08]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\6N9UBKKU\\Pang et al_2015_Predicting Vulnerable Software Components through N-Gram Analysis and.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\ZKD3IJ3Z\\7424372.html}
}

@misc{perryUsersWriteMore2022,
  title = {Do {{Users Write More Insecure Code}} with {{AI Assistants}}?},
  author = {Perry, Neil and Srivastava, Megha and Kumar, Deepak and Boneh, Dan},
  year = {2022},
  month = dec,
  number = {arXiv:2211.03622},
  eprint = {2211.03622},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2211.03622},
  url = {http://arxiv.org/abs/2211.03622},
  urldate = {2023-06-20},
  abstract = {We conduct the first large-scale user study examining how users interact with an AI Code assistant to solve a variety of security related tasks across different programming languages. Overall, we find that participants who had access to an AI assistant based on OpenAI's codex-davinci-002 model wrote significantly less secure code than those without access. Additionally, participants with access to an AI assistant were more likely to believe they wrote secure code than those without access to the AI assistant. Furthermore, we find that participants who trusted the AI less and engaged more with the language and format of their prompts (e.g. re-phrasing, adjusting temperature) provided code with fewer security vulnerabilities. Finally, in order to better inform the design of future AI-based Code assistants, we provide an in-depth analysis of participants' language and interaction behavior, as well as release our user interface as an instrument to conduct similar studies in the future.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Finished,Student/Academia},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\23DMRNZV\\Perry et al_2022_Do Users Write More Insecure Code with AI Assistants.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\U3YVRLSC\\2211.html}
}

@misc{pradelNeuralSoftwareAnalysis2021,
  title = {Neural {{Software Analysis}}},
  author = {Pradel, Michael and Chandra, Satish},
  year = {2021},
  month = apr,
  number = {arXiv:2011.07986},
  eprint = {2011.07986},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2011.07986},
  url = {http://arxiv.org/abs/2011.07986},
  urldate = {2023-01-09},
  abstract = {Many software development problems can be addressed by program analysis tools, which traditionally are based on precise, logical reasoning and heuristics to ensure that the tools are practical. Recent work has shown tremendous success through an alternative way of creating developer tools, which we call neural software analysis. The key idea is to train a neural machine learning model on numerous code examples, which, once trained, makes predictions about previously unseen code. In contrast to traditional program analysis, neural software analysis naturally handles fuzzy information, such as coding conventions and natural language embedded in code, without relying on manually encoded heuristics. This article gives an overview of neural software analysis, discusses when to (not) use it, and presents three example analyses. The analyses address challenging software development problems: bug detection, type prediction, and code completion. The resulting tools complement and outperform traditional program analyses, and are used in industrial practice.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Programming Languages,Computer Science - Software Engineering},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\URYBIPTX\\Pradel_Chandra_2021_Neural Software Analysis.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\IC9XGF5Q\\2011.html}
}

@article{russellAutomatedVulnerabilityDetection2018,
  title = {Automated {{Vulnerability Detection}} in {{Source Code Using Deep Representation Learning}}},
  author = {Russell, Rebecca and Kim, Louis and Hamilton, Lei and Lazovich, Tomo and Harer, Jacob and Ozdemir, Onur and Ellingwood, Paul and McConley, Marc},
  year = {2018},
  month = dec,
  journal = {2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  pages = {757--762},
  publisher = {IEEE},
  address = {Orlando, FL},
  doi = {10.1109/ICMLA.2018.00120},
  url = {https://ieeexplore.ieee.org/document/8614145/},
  urldate = {2023-02-01},
  abstract = {Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. We leveraged the wealth of C and C++ open-source code available to develop a largescale function-level vulnerability detection system using machine learning. To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. Using these datasets, we developed a fast and scalable vulnerability detection tool based on deep feature representation learning that directly interprets lexed source code. We evaluated our tool on code from both real software packages and the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature representation learning on source code is a promising approach for automated software vulnerability detection.},
  isbn = {9781538668054},
  annotation = {152 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\SUFLNQPT\Russell et al_2018_Automated Vulnerability Detection in Source Code Using Deep Representation.pdf}
}

@inproceedings{sandersAnalysisSoftwareVulnerabilities2024,
  title = {Analysis of {{Software Vulnerabilities Introduced}} in {{Programming Submissions Across Curriculum}} at {{Two Higher Education Institutions}}},
  booktitle = {2024 {{IEEE Frontiers}} in {{Education Conference}} ({{FIE}})},
  author = {Sanders, Andrew and Walia, Gursimran Singh and Allen, Andrew},
  year = {2024},
  month = oct,
  abstract = {This full research paper describes the analysis of common software vulnerabilities that are introduced by students enrolled in four-year computing and cybersecurity majors from two different higher education institutions in Georgia.},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\5ME2C7HN\Sanders et al_Analysis of Software Vulnerabilities Introduced in Programming Submissions.pdf}
}

@article{sandersAssessingCommonSoftware2024,
  title = {Assessing {{Common Software Vulnerabilities}} in {{Undergraduate Computer Science Assignments}}},
  author = {Sanders, Andrew and {G. S. Walia} and Allen, Andrew},
  year = {2024},
  month = feb,
  journal = {Journal of The Colloquium for Information Systems Security Education},
  volume = {11},
  number = {1},
  pages = {8},
  issn = {2641-4554, 2641-4546},
  doi = {10.53735/cisse.v11i1.179},
  url = {https://cisse.info/journal/index.php/cisse/article/view/179},
  urldate = {2024-05-17},
  abstract = {As the demand for secure coding education grows, there is a need for improvements in how secure coding is taught and in preparing students to develop more secure software. As time in a Computer Science classroom is finite, educational efforts should be placed on targeting the most common types of vulnerabilities to better prepare students to avoid common security pitfalls in coding. Existing research in this area mainly focuses on developing vulnerability detection tools rather than analyzing the types of commonly produced vulnerabilities by students. Limited research exists in determining common student-produced vulnerabilities, and the available studies differ from the types of vulnerabilities that are researched in vulnerability detection literature. Our research works to further establish the types of vulnerabilities produced by students by using a static analysis tool on assignment code submissions in an undergraduate Programming II (CS2) course. We present our findings on what types of vulnerabilities are commonly produced by students and contrast them with what is commonly researched in the literature. We find there is little overlap between the vulnerability types reported by our study and other studies in the research area. This research has potential implications for secure coding education in a Computer Science curriculum. Further work should be done to establish the contexts in which specific vulnerability types are more likely to be produced and how to best teach students to avoid producing these vulnerabilities.},
  copyright = {All rights reserved},
  keywords = {Cyber-Security Education,Secure Coding Education,Vulnerability Analysis},
  annotation = {1 citations (Crossref) [2024-07-01]},
  file = {C:\Users\Andrew\Zotero\storage\LTC7R35L\Sanders et al_2024_Assessing Common Software Vulnerabilities in Undergraduate Computer Science.pdf}
}

@misc{sandovalLostUserStudy2023,
  title = {Lost at {{C}}: {{A User Study}} on the {{Security Implications}} of {{Large Language Model Code Assistants}}},
  shorttitle = {Lost at {{C}}},
  author = {Sandoval, Gustavo and Pearce, Hammond and Nys, Teo and Karri, Ramesh and Garg, Siddharth and {Dolan-Gavitt}, Brendan},
  year = {2023},
  month = feb,
  number = {arXiv:2208.09727},
  eprint = {2208.09727},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.09727},
  url = {http://arxiv.org/abs/2208.09727},
  urldate = {2023-06-20},
  abstract = {Large Language Models (LLMs) such as OpenAI Codex are increasingly being used as AI-based coding assistants. Understanding the impact of these tools on developers' code is paramount, especially as recent work showed that LLMs may suggest cybersecurity vulnerabilities. We conduct a security-driven user study (N=58) to assess code written by student programmers when assisted by LLMs. Given the potential severity of low-level bugs as well as their relative frequency in real-world projects, we tasked participants with implementing a singly-linked 'shopping list' structure in C. Our results indicate that the security impact in this setting (low-level C with pointer and array manipulations) is small: AI-assisted users produce critical security bugs at a rate no greater than 10\% more than the control, indicating the use of LLMs does not introduce new security risks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\ZAAQLYIR\\Sandoval et al_2023_Lost at C.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\FQEQP2Y4\\2208.html}
}

@misc{SecurityHotspot,
  title = {Security Hotspot},
  url = {https://docs.sonarqube.org/latest/user-guide/security-hotspots/},
  urldate = {2023-06-08},
  file = {C:\Users\Andrew\Zotero\storage\IQM5JHE8\security-hotspots.html}
}

@misc{SEICERTCoding2016,
  title = {{{SEI CERT C Coding Standard}}: {{Rules}} for {{Developing Safe}}, {{Reliable}}, and {{Secure Systems}} (2016 {{Edition}})},
  shorttitle = {{{SEI CERT C Coding Standard}}},
  year = {2016},
  month = jun,
  url = {https://insights.sei.cmu.edu/library/sei-cert-c-coding-standard-rules-for-developing-safe-reliable-and-secure-systems-2016-edition/},
  urldate = {2024-09-11},
  abstract = {In this online download, the CERT Secure Coding Team describes the root causes of common software vulnerabilities, how they can be exploited, the potential consequences, and secure alternatives.},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\ZSZEQEED\sei-cert-c-coding-standard-rules-for-developing-safe-reliable-and-secure-systems-2016-edition.html}
}

@misc{sonarsourceIssues,
  title = {Issues},
  author = {{SonarSource}},
  url = {https://docs.sonarsource.com/sonarqube/latest/user-guide/issues/},
  urldate = {2023-07-12},
  file = {C:\Users\Andrew\Zotero\storage\5J3UUTKQ\issues.html}
}

@article{sonnekalbDeepSecurityAnalysis2021,
  title = {Deep Security Analysis of Program Code},
  author = {Sonnekalb, Tim and Heinze, Thomas S. and M{\"a}der, Patrick},
  year = {2021},
  month = oct,
  journal = {Empirical Software Engineering},
  volume = {27},
  number = {1},
  pages = {2},
  issn = {1573-7616},
  doi = {10.1007/s10664-021-10029-x},
  url = {https://doi.org/10.1007/s10664-021-10029-x},
  urldate = {2022-09-18},
  abstract = {Due to the continuous digitalization of our society, distributed and web-based applications become omnipresent and making them more secure gains paramount relevance. Deep learning (DL) and its representation learning approach are increasingly been proposed for program code analysis potentially providing a powerful means in making software systems less vulnerable. This systematic literature review (SLR) is aiming for a thorough analysis and comparison of 32 primary studies on DL-based vulnerability analysis of program code. We found a rich variety of proposed analysis approaches, code embeddings and network topologies. We discuss these techniques and alternatives in detail. By compiling commonalities and differences in the approaches, we identify the current state of research in this area and discuss future directions. We also provide an overview of publicly available datasets in order to foster a stronger benchmarking of approaches. This SLR provides an overview and starting point for researchers interested in deep vulnerability analysis on program code.},
  langid = {english},
  keywords = {Code inspection,Deep learning,Finished,Software security,Supervised learning,Vulnerability detection},
  annotation = {2 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\FJA3WV7Z\Sonnekalb et al_2021_Deep security analysis of program code.pdf}
}

@article{steenhoekEmpiricalStudyDeep2022,
  title = {An {{Empirical Study}} of {{Deep Learning Models}} for {{Vulnerability Detection}}},
  author = {Steenhoek, Benjamin and Rahman, Md Mahbubur and Jiles, Richard and Le, Wei},
  year = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2212.08109},
  url = {https://arxiv.org/abs/2212.08109},
  urldate = {2023-02-01},
  abstract = {Deep learning (DL) models of code have recently reported great progress for vulnerability detection. In some cases, DL-based models have outperformed static analysis tools. Although many great models have been proposed, we do not yet have a good understanding of these models. This limits the further advancement of model robustness, debugging, and deployment for the vulnerability detection. In this paper, we surveyed and reproduced 9 state-of-the-art (SOTA) deep learning models on 2 widely used vulnerability detection datasets: Devign and MSR. We investigated 6 research questions in three areas, namely model capabilities, training data, and model interpretation. We experimentally demonstrated the variability between different runs of a model and the low agreement among different models' outputs. We investigated models trained for specific types of vulnerabilities compared to a model that is trained on all the vulnerabilities at once. We explored the types of programs DL may consider "hard" to handle. We investigated the relations of training data sizes and training data composition with model performance. Finally, we studied model interpretations and analyzed important features that the models used to make predictions. We believe that our findings can help better understand model results, provide guidance on preparing training data, and improve the robustness of the models. All of our datasets, code, and results are available at https://figshare.com/s/284abfba67dba448fdc2.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Cryptography and Security (cs.CR),FOS: Computer and information sciences,Machine Learning (cs.LG),Software Engineering (cs.SE)},
  file = {C:\Users\Andrew\Zotero\storage\7D5XK674\Steenhoek et al_2022_An Empirical Study of Deep Learning Models for Vulnerability Detection.pdf}
}

@article{steidlQualityAnalysisSource2013,
  title = {Quality Analysis of Source Code Comments},
  author = {Steidl, Daniela and Hummel, Benjamin and Juergens, Elmar},
  year = {2013},
  month = may,
  journal = {2013 21st International Conference on Program Comprehension (ICPC)},
  pages = {83--92},
  publisher = {IEEE},
  address = {San Francisco, CA, USA},
  doi = {10.1109/ICPC.2013.6613836},
  url = {http://ieeexplore.ieee.org/document/6613836/},
  urldate = {2024-11-13},
  abstract = {A significant amount of source code in software systems consists of comments, i. e., parts of the code which are ignored by the compiler. Comments in code represent a main source for system documentation and are hence key for source code understanding with respect to development and maintenance. Although many software developers consider comments to be crucial for program understanding, existing approaches for software quality analysis ignore system commenting or make only quantitative claims. Hence, current quality analyzes do not take a significant part of the software into account. In this work, we present a first detailed approach for quality analysis and assessment of code comments. The approach provides a model for comment quality which is based on different comment categories. To categorize comments, we use machine learning on Java and C/C++ programs. The model comprises different quality aspects: by providing metrics tailored to suit specific categories, we show how quality aspects of the model can be assessed. The validity of the metrics is evaluated with a survey among 16 experienced software developers, a case study demonstrates the relevance of the metrics in practice.},
  isbn = {9781467330923}
}

@article{tabassumEvaluatingTwoMethods2018,
  title = {Evaluating {{Two Methods}} for {{Integrating Secure Programming Education}}},
  author = {Tabassum, Madiha and Watson, Stacey and Chu, Bill and Lipford, Heather Richter},
  year = {2018},
  month = feb,
  journal = {Proceedings of the 49th ACM Technical Symposium on Computer Science Education},
  pages = {390--395},
  publisher = {ACM},
  address = {Baltimore Maryland USA},
  doi = {10.1145/3159450.3159511},
  url = {https://dl.acm.org/doi/10.1145/3159450.3159511},
  urldate = {2022-12-15},
  abstract = {Security vulnerabilities are still prevalent in today's software, yet many can be prevented with standard secure programming techniques. Thus, educators of future developers need to teach students not just how to program, but how to program securely. Many researchers advocate integrating secure programming knowledge and skills across the computer science curriculum. In this paper, we report the results of a study comparing two such methods: our own tool ESIDE, which provides students with security warnings on assignment code, and a security-clinic approach, a one-on-one session with a teaching assistant. Both methods suffered from challenges in incentivizing students to incorporate secure programming techniques into their code. We discuss the relative strengths and weaknesses of these methods, and the challenges of timing and motivation of secure programming education.},
  isbn = {9781450351034},
  langid = {english},
  keywords = {Finished},
  annotation = {6 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\CPMY2NTD\\Tabassum et al_2018_Evaluating Two Methods for Integrating Secure Programming Education.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\HQI4B9WI\\Tabassum et al_2018_Evaluating Two Methods for Integrating Secure Programming Education.pdf}
}

@article{tambergHarnessingLargeLanguage2024,
  title = {Harnessing {{Large Language Models}} for {{Software Vulnerability Detection}}: {{A Comprehensive Benchmarking Study}}},
  shorttitle = {Harnessing {{Large Language Models}} for {{Software Vulnerability Detection}}},
  author = {Tamberg, Karl and Bahsi, Hayretdin},
  year = {2024},
  journal = {ArXiv},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2405.15614},
  url = {https://arxiv.org/abs/2405.15614},
  urldate = {2024-11-13},
  abstract = {Despite various approaches being employed to detect vulnerabilities, the number of reported vulnerabilities shows an upward trend over the years. This suggests the problems are not caught before the code is released, which could be caused by many factors, like lack of awareness, limited efficacy of the existing vulnerability detection tools or the tools not being user-friendly. To help combat some issues with traditional vulnerability detection tools, we propose using large language models (LLMs) to assist in finding vulnerabilities in source code. LLMs have shown a remarkable ability to understand and generate code, underlining their potential in code-related tasks. The aim is to test multiple state-of-the-art LLMs and identify the best prompting strategies, allowing extraction of the best value from the LLMs. We provide an overview of the strengths and weaknesses of the LLM-based approach and compare the results to those of traditional static analysis tools. We find that LLMs can pinpoint many more issues than traditional static analysis tools, outperforming traditional tools in terms of recall and F1 scores. The results should benefit software developers and security analysts responsible for ensuring that the code is free of vulnerabilities.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Artificial Intelligence (cs.AI),Cryptography and Security (cs.CR),FOS: Computer and information sciences,Software Engineering (cs.SE)},
  file = {C:\Users\Andrew\Zotero\storage\IBE5MKQ7\Tamberg and Bahsi - 2024 - Harnessing Large Language Models for Software Vulnerability Detection A Comprehensive Benchmarking.pdf}
}

@inproceedings{taylorSecurityInjectionsModules2011,
  title = {Security Injections: Modules to Help Students Remember, Understand, and Apply Secure Coding Techniques},
  shorttitle = {Security Injections},
  booktitle = {Proceedings of the 16th Annual Joint Conference on {{Innovation}} and Technology in Computer Science Education - {{ITiCSE}} '11},
  author = {Taylor, Blair and Kaza, Siddharth},
  year = {2011},
  pages = {3},
  publisher = {ACM Press},
  address = {Darmstadt, Germany},
  doi = {10.1145/1999747.1999752},
  url = {http://portal.acm.org/citation.cfm?doid=1999747.1999752},
  urldate = {2022-12-15},
  abstract = {With our global reliance on software, secure and robust programming has never been more important. Yet academic institutions have been slow to add secure coding to the curriculum. We present a model using checklist-based security injection modules to increase student awareness and ability to apply secure coding principles, specifically - identify, understand, and correct key security issues in code. The model is evaluated by mapping assessment questions to the cognitive dimension of the revised Bloom's taxonomy. Experiments with students in four sections of CS0 and CS1 show that students using our modules perform significantly better at remembering, understanding and applying secure coding concepts. Students exposed to the modules also show increased ability to write code to address specific security issues.},
  isbn = {978-1-4503-0697-3},
  langid = {english},
  keywords = {Finished},
  annotation = {22 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\375HQTWW\\Taylor_Kaza_2011_Security injections.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\GJFTJFBG\\Taylor_Kaza_2011_Security injections.pdf}
}

@inproceedings{taylorTeachingSecureCoding2013,
  title = {Teaching Secure Coding: The Myths and the Realities},
  shorttitle = {Teaching Secure Coding},
  booktitle = {Proceeding of the 44th {{ACM}} Technical Symposium on {{Computer}} Science Education},
  author = {Taylor, Blair and Bishop, Matt and Hawthorne, Elizabeth and Nance, Kara},
  year = {2013},
  month = mar,
  series = {{{SIGCSE}} '13},
  pages = {281--282},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2445196.2445280},
  url = {https://dl.acm.org/doi/10.1145/2445196.2445280},
  urldate = {2023-06-29},
  abstract = {Teaching secure coding has never been more important. The CS2013 Ironman draft includes Information Assurance and Security as a new Knowledge Area and recommends that security be cross-cutting across all undergraduate computer science curricula. The Summit on Education in Secure Software recommended: 1) increasing the number of faculty who understand the importance of secure programming principles, and will require students to practice them; 2) integrating computer security content into existing technical and non-technical courses; and 3) using innovative teaching methods to strengthen the foundation of computer security knowledge. In this panel, we will speak to these recommendations and the new curricular guidelines and discuss the importance and challenges of teaching secure coding.},
  isbn = {978-1-4503-1868-6},
  keywords = {secure coding,Student/Academia},
  annotation = {4 citations (Crossref) [2023-06-29]},
  file = {C:\Users\Andrew\Zotero\storage\U2T4CCKN\Taylor et al_2013_Teaching secure coding.pdf}
}

@inproceedings{tiagoespinhagasibaSecureCodingEducation2021,
  title = {Is {{Secure Coding Education}} in the {{Industry Needed}}? {{An Investigation Through}} a {{Large Scale Survey}}},
  shorttitle = {Is {{Secure Coding Education}} in the {{Industry Needed}}?},
  booktitle = {2021 {{IEEE}}/{{ACM}} 43rd {{International Conference}} on {{Software Engineering}}: {{Software Engineering Education}} and {{Training}} ({{ICSE-SEET}})},
  author = {{Tiago Espinha Gasiba} and {Ulrike Lechner} and {Maria Pinto-Albuquerque} and {Daniel M{\'e}ndez}},
  year = {2021},
  month = may,
  pages = {241--252},
  doi = {10.1109/ICSE-SEET52601.2021.00034},
  url = {https://ieeexplore.ieee.org/document/9402184},
  urldate = {2024-06-03},
  abstract = {The Department of Homeland Security in the United States estimates that 90\% of software vulnerabilities can be traced back to defects in design and software coding. The financial impact of these vulnerabilities has been shown to exceed 380 million USD in industrial control systems alone. Since software developers write software, they also introduce these vulnerabilities into the source code. However, secure coding guidelines exist to prevent software developers from writing vulnerable code. This study focuses on the human factor, the software developer, and secure coding, in particular secure coding guidelines. We want to understand the software developers' awareness and compliance to secure coding guidelines and why, if at all, they aren't compliant or aware. We base our results on a large-scale survey on secure coding guidelines, with more than 190 industrial software developers. Our work's main contribution motivates the need to educate industrial software developers on secure coding guidelines, and it gives a list of fifteen actionable items to be used by practitioners in the industry. We also make our raw data openly available for further research.},
  keywords = {awareness,education,Encoding,Guidelines,Industries,industry,secure coding guidelines,Software,software developers,survey,Terrorism,Tools,training,US Government},
  annotation = {4 citations (Crossref) [2024-06-03]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\SZFJ9F5D\\Espinha Gasiba et al_2021_Is Secure Coding Education in the Industry Needed.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\2FXZCTM5\\9402184.html}
}

@inproceedings{tufanoWhenWhyYour2015,
  title = {When and {{Why Your Code Starts}} to {{Smell Bad}}},
  booktitle = {2015 {{IEEE}}/{{ACM}} 37th {{IEEE International Conference}} on {{Software Engineering}}},
  author = {Tufano, Michele and Palomba, Fabio and Bavota, Gabriele and Oliveto, Rocco and Di Penta, Massimiliano and De Lucia, Andrea and Poshyvanyk, Denys},
  year = {2015},
  month = may,
  volume = {1},
  pages = {403--414},
  issn = {1558-1225},
  doi = {10.1109/ICSE.2015.59},
  url = {https://ieeexplore.ieee.org/document/7194592/?arnumber=7194592},
  urldate = {2024-09-12},
  abstract = {In past and recent years, the issues related to managing technical debt received significant attention by researchers from both industry and academia. There are several factors that contribute to technical debt. One of these is represented by code bad smells, i.e., Symptoms of poor design and implementation choices. While the repercussions of smells on code quality have been empirically assessed, there is still only anecdotal evidence on when and why bad smells are introduced. To fill this gap, we conducted a large empirical study over the change history of 200 open source projects from different software ecosystems and investigated when bad smells are introduced by developers, and the circumstances and reasons behind their introduction. Our study required the development of a strategy to identify smell-introducing commits, the mining of over 0.5M commits, and the manual analysis of 9,164 of them (i.e., Those identified as smell-introducing). Our findings mostly contradict common wisdom stating that smells are being introduced during evolutionary tasks. In the light of our results, we also call for the need to develop a new generation of recommendation systems aimed at properly planning smell refactoring activities.},
  keywords = {Androids,bad code smells,Ecosystems,empirical study,History,Humanoid robots,Maintenance engineering,Measurement,mining software repositories,Software,Vulnerability Research},
  annotation = {128 citations (Crossref) [2024-09-12]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\9RPHT9FM\\Tufano et al_2015_When and Why Your Code Starts to Smell Bad.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\9BT84QVG\\7194592.html}
}

@inproceedings{valdemarsvabenskyWhatAreCybersecurity2020,
  title = {What {{Are Cybersecurity Education Papers About}}? {{A Systematic Literature Review}} of {{SIGCSE}} and {{ITiCSE Conferences}}},
  shorttitle = {What {{Are Cybersecurity Education Papers About}}?},
  booktitle = {Proceedings of the 51st {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {{Valdemar {\v S}v{\'a}bensk{\'y}} and {Jan Vykopal} and {Pavel {\v C}eleda}},
  year = {2020},
  month = feb,
  series = {{{SIGCSE}} '20},
  pages = {2--8},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3328778.3366816},
  url = {https://doi.org/10.1145/3328778.3366816},
  urldate = {2022-12-13},
  abstract = {Cybersecurity is now more important than ever, and so is education in this field. However, the cybersecurity domain encompasses an extensive set of concepts, which can be taught in different ways and contexts. To understand the state of the art of cybersecurity education and related research, we examine papers from the ACM SIGCSE and ACM ITiCSE conferences. From 2010 to 2019, a total of 1,748 papers were published at these conferences, and 71 of them focus on cybersecurity education. The papers discuss courses, tools, exercises, and teaching approaches. For each paper, we map the covered topics, teaching context, evaluation methods, impact, and the community of authors. We discovered that the technical topic areas are evenly covered (the most prominent being secure programming, network security, and offensive security), and human aspects, such as privacy and social engineering, are present as well. The interventions described in SIGCSE and ITiCSE papers predominantly focus on tertiary education in the USA. The subsequent evaluation mostly consists of collecting students' subjective perceptions via questionnaires. However, less than a third of the papers provide supplementary materials for other educators, and none of the authors published their dataset. Our results provide orientation in the area, a synthesis of trends, and implications for further research. Therefore, they are relevant for instructors, researchers, and anyone new in the field of cybersecurity education. The information we collected and synthesized from individual papers are organized in a publicly available dataset.},
  isbn = {978-1-4503-6793-6},
  keywords = {cybersecurity education,Finished,iticse community,sigcse community,Student/Academia,survey,systematic literature review,systematic mapping study},
  annotation = {25 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\M9MCUC6P\Å vÃ¡benskÃ½ et al_2020_What Are Cybersecurity Education Papers About.pdf}
}

@article{verdiEmpiricalStudyVulnerabilities2022,
  title = {An {{Empirical Study}} of {{C}}++ {{Vulnerabilities}} in {{Crowd-Sourced Code Examples}}},
  author = {Verdi, Morteza and Sami, Ashkan and Akhondali, Jafar and Khomh, Foutse and Uddin, Gias and Motlagh, Alireza Karami},
  year = {2022},
  month = may,
  journal = {IEEE Transactions on Software Engineering},
  volume = {48},
  number = {5},
  pages = {1497--1514},
  issn = {1939-3520},
  doi = {10.1109/TSE.2020.3023664},
  abstract = {Software developers share programming solutions in Q\&A sites like Stack Overflow, Stack Exchange, Android forum, and so on. The reuse of crowd-sourced code snippets can facilitate rapid prototyping. However, recent research shows that the shared code snippets may be of low quality and can even contain vulnerabilities. This paper aims to understand the nature and the prevalence of security vulnerabilities in crowd-sourced code examples. To achieve this goal, we investigate security vulnerabilities in the C++ code snippets shared on Stack Overflow over a period of 10 years. In collaborative sessions involving multiple human coders, we manually assessed each code snippet for security vulnerabilities following CWE (Common Weakness Enumeration) guidelines. From the 72,483 reviewed code snippets used in at least one project hosted on GitHub, we found a total of 99 vulnerable code snippets categorized into 31 types. Many of the investigated code snippets are still not corrected on Stack Overflow. The 99 vulnerable code snippets found in Stack Overflow were reused in a total of 2859 GitHub projects. To help improve the quality of code snippets shared on Stack Overflow, we developed a browser extension that allows Stack Overflow users to be notified for vulnerabilities in code snippets when they see them on the platform.},
  keywords = {Androids,C++,C++ languages,GitHub,Humanoid robots,Open source software,Security,software security,SOTorrent,Stack overflow,Tools,vulnerability evolution,vulnerability migration},
  annotation = {10 citations (Crossref) [2023-02-16]},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\YGSSBU2H\\Verdi et al_2022_An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\QGBPFVBQ\\9195034.html}
}

@misc{verizonVerizon2023Data,
  title = {Verizon 2023 {{Data Breach Investigations Report}}},
  author = {{Verizon}},
  journal = {Verizon Business},
  url = {https://www.verizon.com/business/resources/reports/dbir/},
  urldate = {2024-10-30},
  abstract = {Reduce cyber risks with insights from the 2024 Data Breach Investigations Report (DBIR) from Verizon. Read the official report today.},
  langid = {english},
  keywords = {Finished,Industry},
  file = {C:\Users\Andrew\Zotero\storage\AICGDQQH\dbir.html}
}

@inproceedings{votipkaUnderstandingSecurityMistakes2020a,
  title = {Understanding Security Mistakes Developers Make: {{Qualitative}} Analysis from {{Build It}}, {{Break It}}, {{Fix It}}},
  shorttitle = {Understanding Security Mistakes Developers Make},
  booktitle = {29th {{USENIX Security Symposium}} ({{USENIX Security}} 20)},
  author = {Votipka, Daniel and Fulton, Kelsey R. and Parker, James and Hou, Matthew and Mazurek, Michelle L. and Hicks, Michael},
  year = {2020},
  pages = {109--126},
  url = {https://www.usenix.org/conference/usenixsecurity20/presentation/votipka-understanding},
  urldate = {2023-10-06},
  isbn = {978-1-939133-17-5},
  langid = {english},
  file = {C:\Users\Andrew\Zotero\storage\K3WD4HLV\Votipka et al_2020_Understanding security mistakes developers make.pdf}
}

@article{wangDeepVulSeekerNovelVulnerability2022,
  title = {{{DeepVulSeeker}}: {{A Novel Vulnerability Identification Framework}} via {{Code Graph Structure}} and {{Pre-training Mechanism}}},
  shorttitle = {{{DeepVulSeeker}}},
  author = {Wang, Jin and Xiao, Hui and Zhong, Shuwen and Xiao, Yinhao},
  year = {2022},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2211.13097},
  url = {https://arxiv.org/abs/2211.13097},
  urldate = {2023-04-07},
  abstract = {Software vulnerabilities can pose severe harms to a computing system. They can lead to system crash, privacy leakage, or even physical damage. Correctly identifying vulnerabilities among enormous software codes in a timely manner is so far the essential prerequisite to patch them. Unfortantely, the current vulnerability identification methods, either the classic ones or the deep-learning-based ones, have several critical drawbacks, making them unable to meet the present-day demands put forward by the software industry. To overcome the drawbacks, in this paper, we propose DeepVulSeeker, a novel fully automated vulnerability identification framework, which leverages both code graph structures and the semantic features with the help of the recently advanced Graph Representation Self-Attention and pre-training mechanisms. Our experiments show that DeepVulSeeker not only reaches an accuracy as high as 0.99 on traditional CWE datasets, but also outperforms all other exisiting methods on two highly-complicated datasets. We also testified DeepVulSeeker based on three case studies, and found that DeepVulSeeker is able to understand the implications of the vulnerbilities. We have fully implemented DeepVulSeeker and open-sourced it for future follow-up research.},
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  keywords = {Cryptography and Security (cs.CR),FOS: Computer and information sciences},
  file = {C:\Users\Andrew\Zotero\storage\BSYB56KR\Wang et al_2022_DeepVulSeeker.pdf}
}

@misc{warneckeEvaluatingExplanationMethods2020,
  title = {Evaluating {{Explanation Methods}} for {{Deep Learning}} in {{Security}}},
  author = {Warnecke, Alexander and Arp, Daniel and Wressnegger, Christian and Rieck, Konrad},
  year = {2020},
  month = apr,
  number = {arXiv:1906.02108},
  eprint = {1906.02108},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1906.02108},
  url = {http://arxiv.org/abs/1906.02108},
  urldate = {2023-01-11},
  abstract = {Deep learning is increasingly used as a building block of security systems. Unfortunately, neural networks are hard to interpret and typically opaque to the practitioner. The machine learning community has started to address this problem by developing methods for explaining the predictions of neural networks. While several of these approaches have been successfully applied in the area of computer vision, their application in security has received little attention so far. It is an open question which explanation methods are appropriate for computer security and what requirements they need to satisfy. In this paper, we introduce criteria for comparing and evaluating explanation methods in the context of computer security. These cover general properties, such as the accuracy of explanations, as well as security-focused aspects, such as the completeness, efficiency, and robustness. Based on our criteria, we investigate six popular explanation methods and assess their utility in security systems for malware detection and vulnerability discovery. We observe significant differences between the methods and build on these to derive general recommendations for selecting and applying explanation methods in computer security.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Andrew\\Zotero\\storage\\Y4J8SQU9\\Warnecke et al_2020_Evaluating Explanation Methods for Deep Learning in Security.pdf;C\:\\Users\\Andrew\\Zotero\\storage\\2RFQMP85\\1906.html}
}

@inproceedings{wohlinGuidelinesSnowballingSystematic2014,
  title = {Guidelines for Snowballing in Systematic Literature Studies and a Replication in Software Engineering},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}}},
  author = {Wohlin, Claes},
  year = {2014},
  month = may,
  series = {{{EASE}} '14},
  pages = {1--10},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2601248.2601268},
  url = {https://doi.org/10.1145/2601248.2601268},
  urldate = {2023-01-10},
  abstract = {Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably. Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review. Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches. Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review. Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.},
  isbn = {978-1-4503-2476-2},
  keywords = {Finished,replication,snowball search,snowballing,systematic literature review,systematic mapping studies},
  annotation = {1022 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\F5F72MB8\Wohlin_2014_Guidelines for snowballing in systematic literature studies and a replication.pdf}
}

@inproceedings{yangSurveyResearchCode2019,
  title = {A {{Survey}} on {{Research}} of {{Code Comment}}},
  booktitle = {Proceedings of the 2019 3rd {{International Conference}} on {{Management Engineering}}, {{Software Engineering}} and {{Service Sciences}}},
  author = {Yang, Bai and Liping, Zhang and Fengrong, Zhao},
  year = {2019},
  month = jan,
  series = {{{ICMSS}} 2019},
  pages = {45--51},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3312662.3312710},
  url = {https://dl.acm.org/doi/10.1145/3312662.3312710},
  urldate = {2024-11-13},
  abstract = {Code comments are one of the effective means for assisting programmers to understand the source code. High-quality code comments play an important role in areas such as software maintenance and software reuse. Good code comments can help programmers understand the role of source code and facilitate comprehension of programs and software maintenance tasks quickly. But in reality, most programmers only pay attention to the code and ignore comments and documents, which greatly reduce the program's readability and maintainability. This paper has compiled the relevant research on code comments so far, mainly including four aspects: automatic generation of code comments, consistency of code comments, classification of code comments, and quality evaluation of code comments. By analyzing relevant methods in this research field, it provides more complete information for future research.},
  isbn = {978-1-4503-6189-7},
  file = {C:\Users\Andrew\Zotero\storage\KXI34IUZ\Yang et al. - 2019 - A Survey on Research of Code Comment.pdf}
}

@article{yen-hunghuAssessingJavaCoding2017,
  title = {Assessing {{Java Coding Vulnerabilities}} in {{Undergraduate Software Engineering Education}} by {{Using Open Source Vulnerability Analysis Tools}}},
  author = {{Yen-Hung Hu} and {Thomas Kofi Annan}},
  year = {2017},
  month = feb,
  journal = {Journal of The Colloquium for Information Systems Security Education},
  volume = {4},
  number = {2},
  pages = {33--33},
  issn = {2641-4554},
  url = {https://cisse.info/journal/index.php/cisse/article/view/60},
  urldate = {2023-02-01},
  abstract = {Security and quality are two vital attributes of any software application no matter how infinitesimal it might be. Tackling a software problem by its source is one of the most trusted models used in problem solving approaches. In this paper, we want to ensure that all undergraduate Java learners write codes based on the security and quality guidelines expected in the industry right from the day they start learning ``Hello World!'' in Java. In the research, sample codes getting from several Java books used in teaching Java concepts for undergraduate courses were used as the case study. These sample codes were tested using an open source tool developed based on security and quality guidelines. The tool determines the vulnerability level in any Java code passed as an input to it then it analyzes the code and generates a report indicating the threat level based on the vulnerabilities in the code. The results of this paper will be published and authors of the selected books for the research will be notified with those vulnerabilities in their source codes along with suggestions for fixing those vulnerabilities.},
  copyright = {Copyright (c) 2017 The Colloquium for Information Systems Security Education},
  langid = {english},
  keywords = {Finished,Java,Open Source,Quality,Security,Vulnerability},
  file = {C:\Users\Andrew\Zotero\storage\T2H8FVGK\Hu_Annan_2017_Assessing Java Coding Vulnerabilities in Undergraduate Software Engineering.pdf}
}

@article{yilmazUnderstandingSecurityVulnerabilities2022,
  title = {Understanding Security Vulnerabilities in Student Code: {{A}} Case Study in a Non-Security Course},
  shorttitle = {Understanding Security Vulnerabilities in Student Code},
  author = {Yilmaz, Tolga and Ulusoy, {\"O}zg{\"u}r},
  year = {2022},
  month = mar,
  journal = {Journal of Systems and Software},
  volume = {185},
  pages = {111150},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2021.111150},
  url = {https://www.sciencedirect.com/science/article/pii/S0164121221002430},
  urldate = {2022-09-18},
  abstract = {Secure coding education is quite important for students to acquire the skills to quickly adapt to the evolving threats towards the software they are expected to create once they graduate. Educators are also more aware of this situation and incorporate teaching security in their respective fields. An effective application of this is only possible by cultivating the teaching and learning perspectives. Understanding the security awareness and practice of students is useful as an initial step to create a baseline for teaching methods and content. In this paper, we first survey to investigate how students approach security and what could motivate them to learn and apply security practices. Then, we analyze the source code for 6 semesters of coding assignments for 2 tasks using a source code vulnerability analysis tool. In our analysis, we report the types of vulnerabilities and various aspects between them while incorporating the effect of student grades. We then explore the lexical and structural features of security in student code using data analysis and machine learning. For the lexical analysis, we build a classifier to extract informative features and for the structural analysis, we utilize Syntax Trees to represent code and perform clustering in terms of structural features where clusters themselves yield different vulnerability levels.},
  langid = {english},
  keywords = {Data mining,Finished,Secure coding education,Source code analysis,Student/Academia,Vulnerability analysis},
  annotation = {0 citations (Crossref) [2023-02-16]},
  file = {C:\Users\Andrew\Zotero\storage\T5AVSUGL\Yilmaz_Ulusoy_2022_Understanding security vulnerabilities in student code.pdf}
}

@article{zhangReviewAutomaticSource2024,
  title = {A Review of Automatic Source Code Summarization},
  author = {Zhang, Xuejun and Hou, Xia and Qiao, Xiuming and Song, Wenfeng},
  year = {2024},
  month = oct,
  journal = {Empirical Software Engineering},
  volume = {29},
  number = {6},
  pages = {162},
  issn = {1573-7616},
  doi = {10.1007/s10664-024-10553-6},
  url = {https://doi.org/10.1007/s10664-024-10553-6},
  urldate = {2024-11-13},
  abstract = {Code summarization plays a pivotal role in the field of software engineering by offering developers a concise natural language comprehension of source code semantics. As software complexity continues to escalate, code summarization confronts various challenges, including discrepancies between source code and summarization, the absence of crucial or up-to-date information, and the inefficiency and resource demands of manual summarization. To address these challenges, Automatic Source Code Summarization (ASCS) has garnered widespread attention. This paper presents a comprehensive review and synthesis of ASCS research. It aims to provide an in-depth understanding of the core issues and challenges inherent in each phase of ASCS, illustrated with specific examples and application scenarios. Around of the core phases of ASCS including data collection, source code modeling, the generation of code summaries, and the assessment of their quality, the paper thoroughly compiles and assesses existing datasets, categorizes and examines prevalent source code modeling techniques, and delves into the methods for generating and evaluating the quality of code summaries. Concluding with an exploration of future research avenues and emerging trends, this paper serves as a guide for readers to grasp the cutting-edge developments in this field, enriched by the analysis of pivotal research contributions.},
  langid = {english},
  keywords = {Automatic source code summarization,Code modeling,Data collection,Quality evaluation},
  file = {C:\Users\Andrew\Zotero\storage\SZ66XNFW\Zhang et al. - 2024 - A review of automatic source code summarization.pdf}
}

@article{shenChatGPT2023,
author = {Shen, Yiqiu and Heacock, Laura and Elias, Jonathan and Hentel, Keith                             D. and Reig, Beatriu and Shih, George and Moy, Linda},
title = {ChatGPT and Other Large Language Models Are Double-edged                     Swords},
journal = {Radiology},
volume = {307},
number = {2},
pages = {e230163},
year = {2023},
doi = {10.1148/radiol.230163},
    note ={PMID: 36700838},
URL = { https://doi.org/10.1148/radiol.230163
},
eprint = {  
        https://doi.org/10.1148/radiol.230163
    }
}

@INPROCEEDINGS{akuthotaVulnerabilityDetectionLLM2023,
  author={Akuthota, Vishwanath and Kasula, Raghunandan and Sumona, Sabiha Tasnim and Mohiuddin, Masud and Reza, Md Tanzim and Rahman, Md Mizanur},
  booktitle={2023 IEEE 9th International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE)}, 
  title={Vulnerability Detection and Monitoring Using LLM}, 
  year={2023},
  volume={},
  number={},
  pages={309-314},
  keywords={Measurement;Codes;Computational modeling;Machine learning;Predictive models;Software;Software reliability;Language Model Models (LLMs);Vulnerability;ChatGPT;GPT-3.5-Turbo model;OpenAI},
  doi={10.1109/WIECON-ECE60392.2023.10456393}}

@book{Vygotsky:78,
title = {Mind in Society: Development of Higher Psychological Processes}, 
Publisher = {Harvard University Press}, 
Address = {Cambridge}, 
Year = {1978},
author = {Vygotsky, L.}
}

@article{sweller1988cognitive,
  title={Cognitive load during problem solving: Effects on learning},
  author={Sweller, John},
  journal={Cognitive Science},
  volume={12},
  number={2},
  pages={257--285},
  year={1988},
  publisher={Wiley Online Library}
}

@article{sweller2019cognitive,
  title={Cognitive architecture and instructional design: 20 years later},
  author={Sweller, John and van MerriÃ«nboer, Jeroen JG and Paas, Fred},
  journal={Educational Psychology Review},
  volume={31},
  number={2},
  pages={261--292},
  year={2019},
  publisher={Springer}
}

@book{vygotsky1978mind,
  author    = {Vygotsky, Lev S.},
  title     = {Mind in Society: The Development of Higher Psychological Processes},
  year      = {1978},
  publisher = {Harvard University Press},
  address   = {Cambridge, MA}
}